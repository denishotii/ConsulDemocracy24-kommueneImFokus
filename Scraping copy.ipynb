{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper for 19 Cities\n",
    "\n",
    "This scraper extracts and organizes data into three main DataFrames:\n",
    "1. **`all_projects_df`**: Contains all projects from the websites.\n",
    "   - Columns: `Project URL`, `Project Title`, `Project Description`, `Proposal Count`, `City`\n",
    "\n",
    "2. **`all_proposals_df`**: Contains all proposals under projects.\n",
    "   - Columns: `URL`, `Title`, `Proposed for Project`, `Description`, `Author`, `Comments`, `Supporters`, `City`\n",
    "\n",
    "3. **`all_comments_df`**: Contains all comments under projects and proposals.\n",
    "   - Columns: `URL`, `Project`, `Text`, `Author`, `Likes`, `Dislikes`, `Date`, `City`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# # Updated function to extract proposals from a project page\n",
    "# def extract_proposals(soup, base_url):\n",
    "#     proposals = []\n",
    "#     proposal_items = soup.find_all('div', class_='resource-item proposal-list-item')\n",
    "#     # here we are looking for all the proposals in the page with the class 'resource-item proposal-list-item'\n",
    "\n",
    "#     # For each proposal item, we loop through and extract the relevant information\n",
    "#     for proposal in proposal_items:\n",
    "#         # Extract title by finding the class 'resource-item--title' and getting the text\n",
    "#         title_tag = proposal.find('a', class_='resource-item--title')\n",
    "#         title = title_tag.get_text(strip=True) if title_tag else None\n",
    "\n",
    "#         # Extract URL by finding the class 'resource-item--title' and getting the 'href' attribute (because title is a link)\n",
    "#         url = base_url + title_tag['href'] if title_tag and 'href' in title_tag.attrs else None\n",
    "\n",
    "#         # Extract description by finding the class 'resource-item--description' and getting the text\n",
    "#         description_tag = proposal.find('div', class_='resource-item--description')\n",
    "#         description = description_tag.get_text(strip=True) if description_tag else None\n",
    "\n",
    "#         # Extract author/username by finding the class 'resource-item--author' and getting the text\n",
    "#         author_tag = proposal.find('a', class_='resource-item--author')\n",
    "#         author = author_tag.get_text(strip=True) if author_tag else None\n",
    "\n",
    "#         # Extract number of comments by finding the class 'comments' and getting the text (span is almost like a div, but inline)\n",
    "#         comments_tag = proposal.find('span', class_='comments')\n",
    "#         comments = int(comments_tag.get_text(strip=True).split()[0]) if comments_tag else 0\n",
    "\n",
    "#         # Extract number of supporters by finding the class 'total-supports' and getting the text\n",
    "#         supporters_tag = proposal.find('span', class_='total-supports')\n",
    "#         supporters = int(supporters_tag.get_text(strip=True).split()[0]) if supporters_tag else 0\n",
    "\n",
    "#         # Extract parent project name by finding the class 'breadcrumbs-item' and getting the text\n",
    "#         project_tag = proposal.find('a', class_='breadcrumbs-item')\n",
    "#         proposed_for_project = project_tag.get_text(strip=True) if project_tag else None\n",
    "\n",
    "#         # Append the extracted information to the proposals list. Proposals are dictionaries with keys and values\n",
    "#         proposals.append({\n",
    "#             'URL': url,\n",
    "#             'Title': title,\n",
    "#             'Proposed for Project': proposed_for_project,\n",
    "#             'Description': description,\n",
    "#             'Author': author,\n",
    "#             'Comments': comments,\n",
    "#             'Supporters': supporters,\n",
    "#         })\n",
    "#     return proposals\n",
    "\n",
    "\n",
    "# # Function to extract city name from the base URL\n",
    "# def extract_city_name(base_url):\n",
    "#     # Words to remove from the city name, because URL is not always clean city name and may contain extra words (e.g. mitmachen)\n",
    "#     remove_words = ['mitmachen', 'Mitmachen', 'mitwirken', 'Smarte', 'region', 'unser', 'mitgestalten', 'gestalten', 'machmit', 'dialog', 'consul', 'www', 'de', 'https', 'com']\n",
    "\n",
    "#     # Split the URL into parts (by '.' or '/'), because city name is usually the first relevant part\n",
    "#     parts = base_url.replace('https://', '').replace('http://', '').split('.')\n",
    "#     all_parts = [part.split('/')[0] for part in parts]  # Handle cases where \"/\" exists after domain\n",
    "\n",
    "#     # Remove known unwanted words and empty strings \n",
    "#     filtered_parts = [part for part in all_parts if part.lower() not in remove_words and part]\n",
    "\n",
    "#     # Return the first relevant part (assumes city name is left after filtering) \n",
    "#     city = filtered_parts[0].replace('-', ' ').capitalize() if filtered_parts else \"Unknown\"\n",
    "\n",
    "#     # Because city name is not always first part, we get it by removing all other words (they are usually similar in all URLs)\n",
    "#     for word in remove_words:\n",
    "#         city = city.replace(word, '')\n",
    "\n",
    "#     return city.strip().capitalize()\n",
    "\n",
    "\n",
    "# # Here is the function that scrapes the project page and extracts the project title, description and proposals \n",
    "# def scrape_project_page_with_proposals(url, base_url, city):\n",
    "\n",
    "#     # In that block we request the page and parse it with BeautifulSoup, getting soup object, which contains all the HTML content from the given URL\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code != 200:\n",
    "#         print(f\"Failed to load project page: {url}\")\n",
    "#         return None, []\n",
    "\n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    \n",
    "\n",
    "#     # Extract project title by finding the 'title' tag and getting the text\n",
    "#     title_tag = soup.find('title')\n",
    "#     project_title = title_tag.get_text(strip=True) if title_tag else None\n",
    "\n",
    "#     # Extract project description by finding the 'div' tag with class 'flex-layout' and getting the text\n",
    "#     content_div = soup.find('div', class_='flex-layout')\n",
    "#     description = content_div.get_text(strip=True) if content_div else None\n",
    "\n",
    "#     # Extract proposals by calling the extract_proposals function, which we defined earlier\n",
    "#     proposals = extract_proposals(soup, base_url=base_url)\n",
    "\n",
    "#     # Return a dictionary with the extracted information and the list of proposals\n",
    "#     return {\n",
    "#         'Project URL': url,\n",
    "#         'Project Title': project_title,\n",
    "#         'Project Description': description,\n",
    "#         'Proposal Count': len(proposals),\n",
    "#     }, proposals\n",
    "\n",
    "\n",
    "# # Here is the function that scrapes the main projects page and extracts the project URLs. This function is \"main\" because it calls the scrape_project_page_with_proposals function, which calls the extract_proposals function.\n",
    "# # So the scheme is: scrape_projects_with_proposals(to get project URLs) -> scrape_project_page_with_proposals(to get project data and proposals) -> extract_proposals(to get proposals)\n",
    "# def scrape_projects_with_proposals(main_url, base_url):\n",
    "\n",
    "#     # Here we again request the page and parse it with BeautifulSoup, getting soup object, which contains all the HTML content from the given URL\n",
    "#     response = requests.get(main_url)\n",
    "#     if response.status_code != 200:\n",
    "#         print(f\"Failed to load main projects page: {main_url}\")\n",
    "#         return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#     # Find all project links by finding the 'a' tag with class 'resource-item--title' and getting the 'href' attribute\n",
    "#     links = soup.find_all('a', class_='resource-item--title')\n",
    "#     project_links = [base_url + link['href'] for link in links if 'href' in link.attrs]\n",
    "\n",
    "#     projects = []\n",
    "#     all_proposals = []\n",
    "\n",
    "#     # For each project link, call the scrape_project_page_with_proposals function to get the project data and proposals. Try/except block is used to catch any errors that may occur during scraping\n",
    "\n",
    "#     for project_url in project_links:\n",
    "#         try:\n",
    "#             project_data, proposals = scrape_project_page_with_proposals(\n",
    "#                 project_url, base_url, extract_city_name(base_url)\n",
    "#             )\n",
    "#             if project_data:\n",
    "#                 projects.append(project_data)\n",
    "#                 all_proposals.extend(proposals)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error scraping project at {project_url}: {e}\")\n",
    "\n",
    "#     return pd.DataFrame(projects), pd.DataFrame(all_proposals)\n",
    "\n",
    "# # List of websites to scrape (19 websites with similar structure)\n",
    "# websites = [\n",
    "#     {\"main_url\": \"https://wuerzburg-mitmachen.de/projekts\", \"base_url\": \"https://wuerzburg-mitmachen.de\"},\n",
    "#     {\"main_url\": \"https://mitmachen.siegburg.de/projekts\", \"base_url\": \"https://mitmachen.siegburg.de\"}, \n",
    "#     {\"main_url\": \"https://mitmachen.jena.de/projekts\", \"base_url\": \"https://mitmachen.jena.de\"},\n",
    "#     {\"main_url\": \"https://mitmachgemeinde.de/projekts\", \"base_url\": \"https://mitmachgemeinde.de\"},\n",
    "#     {\"main_url\": \"https://bamberg-gestalten.de/projekts\", \"base_url\": \"https://bamberg-gestalten.de\"},\n",
    "#     {\"main_url\": \"https://mitmachen-pforzheim.de/projekts\", \"base_url\": \"https://mitmachen-pforzheim.de\"},\n",
    "#     {\"main_url\": \"https://bochum-mitgestalten.de/projekts\", \"base_url\": \"https://bochum-mitgestalten.de\"},\n",
    "#     {\"main_url\": \"https://unser.muenchen.de/projekts\", \"base_url\": \"https://unser.muenchen.de\"},\n",
    "#     {\"main_url\": \"https://mitreden.ilzerland.bayern/projekts\", \"base_url\": \"https://mitreden.ilzerland.bayern\"},\n",
    "#     {\"main_url\": \"https://stutensee-mitwirken.de/projekts\", \"base_url\": \"https://stutensee-mitwirken.de\"},\n",
    "#     {\"main_url\": \"https://consul.unterschleissheim.de/projekts\", \"base_url\": \"https://consul.unterschleissheim.de\"},\n",
    "#     {\"main_url\": \"https://machmit.kempten.de/projekts\", \"base_url\": \"https://machmit.kempten.de\"},\n",
    "#     {\"main_url\": \"https://consul.detmold-mitgestalten.de/projekts\", \"base_url\": \"https://consul.detmold-mitgestalten.de\"},\n",
    "#     {\"main_url\": \"https://flensburg-mitmachen.de/projekts\", \"base_url\": \"https://flensburg-mitmachen.de\"},  # Fixed URL\n",
    "#     {\"main_url\": \"https://mitmachen.amberg.de/projekts\", \"base_url\": \"https://mitmachen.amberg.de\"},\n",
    "#     {\"main_url\": \"https://mitmachen.smarte-region-linz.de/projekts\", \"base_url\": \"https://mitmachen.smarte-region-linz.de\"},\n",
    "#     {\"main_url\": \"https://mitgestalten.trier.de/projekts\", \"base_url\": \"https://mitgestalten.trier.de\"},\n",
    "#     {\"main_url\": \"https://machmit.augsburg.de/projekts\", \"base_url\": \"https://machmit.augsburg.de\"}\n",
    "# ]\n",
    "\n",
    "\n",
    "# # Initialize empty DataFrames for all projects and proposals \n",
    "# all_projects_df = pd.DataFrame()\n",
    "# all_proposals_df = pd.DataFrame()\n",
    "\n",
    "# # Main loop to scrape all websites in the list\n",
    "# for site in websites:\n",
    "#     main_url = site[\"main_url\"]\n",
    "#     base_url = site[\"base_url\"]\n",
    "\n",
    "#     city = extract_city_name(base_url)\n",
    "\n",
    "#     try:\n",
    "#         # Scrape projects and proposals\n",
    "#         projects_df, proposals_df = scrape_projects_with_proposals(main_url, base_url)\n",
    "\n",
    "#         # Add a 'City' column to all DataFrames\n",
    "#         projects_df['City'] = city\n",
    "#         proposals_df['City'] = city\n",
    "\n",
    "#         # Append results to the combined DataFrames\n",
    "#         all_projects_df = pd.concat([all_projects_df, projects_df], ignore_index=True)\n",
    "#         all_proposals_df = pd.concat([all_proposals_df, proposals_df], ignore_index=True)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to scrape {main_url} - {e}\")\n",
    "\n",
    "\n",
    "# # Save the results to CSV files\n",
    "# all_projects_df.to_csv('data/all_projects.csv', index=False)\n",
    "# all_proposals_df.to_csv('data/all_proposals.csv', index=False)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_projects_df = pd.read_csv('all_projects.csv')\n",
    "all_proposals_df = pd.read_csv('all_proposals.csv')\n",
    "all_comments_df = pd.read_csv('all_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City\n",
       "Muenchen             120\n",
       "Siegburg              96\n",
       "Amberg                79\n",
       "Detmold               76\n",
       "Kempten               69\n",
       "Mitren                55\n",
       "Wuerzburg             39\n",
       "Pforzheim             35\n",
       "Bamberg               32\n",
       "Unterschleissheim     27\n",
       "Trier                 20\n",
       "Augsburg              17\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_proposals_df['City'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project URL</th>\n",
       "      <th>Project Title</th>\n",
       "      <th>Project Description</th>\n",
       "      <th>Proposal Count</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/grombuehl-zukun...</td>\n",
       "      <td>Energetisches Quartierskonzept f√ºr Gromb√ºhl</td>\n",
       "      <td>Gromb√ºhl 2040 - ein SzenarioDie Stra√üen Gromb√º...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/mobilitaetsplan</td>\n",
       "      <td>Mobilit√§tsplan 2040</td>\n",
       "      <td>Mobilit√§tsplan 2040 f√ºr die Stadt W√ºrzburg: Je...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/zukunftsregion</td>\n",
       "      <td>Zukunftsregion W√ºrzburg</td>\n",
       "      <td>Zukunftsregion W√ºrzburg: Jetzt aktiv mitgestal...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/zukunftskonzept...</td>\n",
       "      <td>Zukunftskonzepte f√ºr die Innenstadt</td>\n",
       "      <td>Wie soll die W√ºrzburger Innenstadt von morgen ...</td>\n",
       "      <td>24</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/klimaanpassung</td>\n",
       "      <td>Klimaanpassung</td>\n",
       "      <td>Klimaanpassungsstrategie f√ºr die Stadt W√ºrzbur...</td>\n",
       "      <td>14</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Project URL  \\\n",
       "0  https://wuerzburg-mitmachen.de/grombuehl-zukun...   \n",
       "1     https://wuerzburg-mitmachen.de/mobilitaetsplan   \n",
       "2      https://wuerzburg-mitmachen.de/zukunftsregion   \n",
       "3  https://wuerzburg-mitmachen.de/zukunftskonzept...   \n",
       "4      https://wuerzburg-mitmachen.de/klimaanpassung   \n",
       "\n",
       "                                 Project Title  \\\n",
       "0  Energetisches Quartierskonzept f√ºr Gromb√ºhl   \n",
       "1                          Mobilit√§tsplan 2040   \n",
       "2                      Zukunftsregion W√ºrzburg   \n",
       "3          Zukunftskonzepte f√ºr die Innenstadt   \n",
       "4                               Klimaanpassung   \n",
       "\n",
       "                                 Project Description  Proposal Count  \\\n",
       "0  Gromb√ºhl 2040 - ein SzenarioDie Stra√üen Gromb√º...               0   \n",
       "1  Mobilit√§tsplan 2040 f√ºr die Stadt W√ºrzburg: Je...               0   \n",
       "2  Zukunftsregion W√ºrzburg: Jetzt aktiv mitgestal...               0   \n",
       "3  Wie soll die W√ºrzburger Innenstadt von morgen ...              24   \n",
       "4  Klimaanpassungsstrategie f√ºr die Stadt W√ºrzbur...              14   \n",
       "\n",
       "        City  \n",
       "0  Wuerzburg  \n",
       "1  Wuerzburg  \n",
       "2  Wuerzburg  \n",
       "3  Wuerzburg  \n",
       "4  Wuerzburg  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_projects_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BurgerBudgets in Jena (2024, 23, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # URLs for the budgets\n",
    "# budget_urls = {\n",
    "#     2024: \"https://mitmachen.jena.de/buergerbudget\",\n",
    "#     2023: \"https://mitmachen.jena.de/buergerbudget-2023\",\n",
    "#     2022: \"https://mitmachen.jena.de/buergerbudget-2022\"\n",
    "# }\n",
    "\n",
    "# # Updated function to scrape and clean a budget table for a given year\n",
    "# def scrape_and_clean_budget_table(url, year):\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code != 200:\n",
    "#         print(f\"Failed to load URL: {url}\")\n",
    "#         return None\n",
    "    \n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#     table = soup.find('table', id='budget-investments-compatible')  # Locate the table by its ID\n",
    "    \n",
    "#     if not table:\n",
    "#         print(f\"No table found for URL: {url}\")\n",
    "#         return None\n",
    "    \n",
    "#     # Extract the total available budget for the year (last <th> in <thead>)\n",
    "#     available_budget_tag = table.find('thead').find_all('th')[-1]  # Find the last <th>\n",
    "#     available_budget = (\n",
    "#         float(re.sub(r'[^\\d.]', '', available_budget_tag.get_text(strip=True))) * 1000\n",
    "#         if available_budget_tag else None\n",
    "#     )\n",
    "    \n",
    "#     # Extract table headers\n",
    "#     headers = [th.get_text(strip=True) for th in table.find('thead').find_all('th')]\n",
    "    \n",
    "#     # Extract table rows\n",
    "#     rows = []\n",
    "#     for tr in table.find('tbody').find_all('tr'):\n",
    "#         # Extract row cells\n",
    "#         cells = [td.get_text(strip=True) for td in tr.find_all('td')]\n",
    "        \n",
    "#         # Check the class of the <tr> tag for \"success\" or \"discarded\"\n",
    "#         approved = 1 if 'success' in tr.get('class', []) else 0\n",
    "        \n",
    "#         # Append cells and approval status\n",
    "#         rows.append(cells + [approved])\n",
    "    \n",
    "#     # Add \"Approved\" column to the headers\n",
    "#     headers.append('Approved')\n",
    "    \n",
    "#     # Create a DataFrame\n",
    "#     df = pd.DataFrame(rows, columns=headers)\n",
    "#     df['Year'] = year  # Add a 'Year' column\n",
    "#     df['Available Budget'] = available_budget  # Add the total budget for the year to every row\n",
    "#     return df\n",
    "\n",
    "# # Scrape and clean tables for all years\n",
    "# budget_dataframes = [\n",
    "#     scrape_and_clean_budget_table(url, year) for year, url in budget_urls.items()\n",
    "# ]\n",
    "\n",
    "# # Combine all dataframes into one\n",
    "# budget_jena_df = pd.concat(budget_dataframes, ignore_index=True)\n",
    "\n",
    "# # Clean and transform the DataFrame\n",
    "# budget_jena_df['Preis'] = budget_jena_df['Preis'].str.extract(r'(\\d+)').astype(float) * 1000\n",
    "# budget_jena_df['Stimmen'] = budget_jena_df['Stimmen'].str.extract(r'(\\d+)').astype(int)\n",
    "\n",
    "# # Rename columns to English\n",
    "# budget_jena_df.rename(columns={\n",
    "#     'Vorschlag Titel': 'Proposal Title',\n",
    "#     'Stimmen': 'Votes',\n",
    "#     'Preis': 'Price',\n",
    "#     'Year': 'Year',\n",
    "#     'Available Budget': 'Budget for this year',\n",
    "#     'Approved': 'Approved'\n",
    "# }, inplace=True)\n",
    "\n",
    "# # Drop unnecessary columns if any remain\n",
    "# budget_jena_df = budget_jena_df.loc[:, ~budget_jena_df.columns.str.contains('Verf√ºgbareBudgetmittel', na=False)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments Scraper\n",
    "\n",
    "This scraper extracts comments for all projects from the `all_projects_df` DataFrame and organizes them into a structured DataFrame:\n",
    "\n",
    "1. **`df_comments`**: Contains all comments associated with projects.\n",
    "   - Columns:\n",
    "     - `URL`: The URL of the project the comment is associated with.\n",
    "     - `Project`: The title of the project the comment is associated with.\n",
    "     - `City`: The city the project belongs to (extracted from the URL).\n",
    "     - `Text`: The content of the comment.\n",
    "     - `Username`: The name of the user who posted the comment.\n",
    "     - `Date`: The date the comment was posted.\n",
    "     - `Likes`: The number of likes the comment received.\n",
    "     - `Dislikes`: The number of dislikes the comment received.\n",
    "     - `Total Votes`: The total votes (likes + dislikes) the comment received.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Good scraper for comments (748 entries comments from 19 cities)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# # Here is the function to extract comments from a single page\n",
    "# def extract_comments_from_page(soup):\n",
    "\n",
    "#     # Initialize an empty list to store the comments and look for the comments section div with class 'comment small-12' (all the comment blocks in similar websites have this class)\n",
    "#     comments_data = []\n",
    "#     comments_section = soup.find_all('div', class_='comment small-12')\n",
    "    \n",
    "#     for comment in comments_section:\n",
    "#         # Extract comment text (clean and remove extra whitespace) by finding the first 'p' tag inside the comment div\n",
    "#         comment_text = comment.find('p').get_text(strip=True) if comment.find('p') else None\n",
    "        \n",
    "#         # Extract username by finding the 'span' tag with class 'user-name' inside the comment div\n",
    "#         username_tag = comment.find('span', class_='user-name')\n",
    "#         username = username_tag.get_text(strip=True) if username_tag else None\n",
    "        \n",
    "#         # Extract date by finding the last 'a' tag inside the 'div' tag with class 'comment-info' (last link is the date)\n",
    "#         date_tag = comment.find('div', class_='comment-info').find_all('a')[-1]\n",
    "#         date = date_tag.get_text(strip=True) if date_tag else None\n",
    "\n",
    "        \n",
    "#         # Extract likes and dislikes (clean and convert to integer) if they exist by finding the 'span' tags with class 'in-favor' and 'against'\n",
    "#         likes_tag = comment.find('span', class_='in-favor')\n",
    "#         likes = int(re.sub(r'\\D', '', likes_tag.get_text(strip=True))) if likes_tag else 0\n",
    "        \n",
    "#         dislikes_tag = comment.find('span', class_='against')\n",
    "#         dislikes = int(re.sub(r'\\D', '', dislikes_tag.get_text(strip=True))) if dislikes_tag else 0\n",
    "        \n",
    "#         # Extract total votes (clean and convert to integer), it was the easiest way to get the total votes\n",
    "#         total_votes = likes + dislikes\n",
    "        \n",
    "#         # Append the extracted information to the comments_data list\n",
    "#         comments_data.append({\n",
    "#             'Text': comment_text,\n",
    "#             'Username': username,\n",
    "#             'Date': date,\n",
    "#             'Likes': likes,\n",
    "#             'Dislikes': dislikes,\n",
    "#             'Total Votes': total_votes\n",
    "#         })\n",
    "#     return comments_data\n",
    "\n",
    "\n",
    "# # Function to extract city name from the base URL to add column 'City' to the comments DataFrame\n",
    "# def extract_city_name(base_url):\n",
    "#     # Words to remove from the city name (most URLs have similar structure and contain these words)\n",
    "#     remove_words = ['mitmachen', 'Mitmachen', 'mitwirken', 'Smarte', 'region', 'unser', 'mitgestalten', 'gestalten', 'machmit', 'dialog', 'consul', 'www', 'de', 'https', 'com']\n",
    "\n",
    "#     # Split the URL into parts (by '.' or '/')\n",
    "#     parts = base_url.replace('https://', '').replace('http://', '').split('.')\n",
    "#     all_parts = [part.split('/')[0] for part in parts]  # Handle cases where \"/\" exists after domain\n",
    "\n",
    "#     # Remove known unwanted words and empty strings\n",
    "#     filtered_parts = [part for part in all_parts if part.lower() not in remove_words and part]\n",
    "\n",
    "#     # Return the first relevant part (assumes city name is left after filtering)\n",
    "#     city = filtered_parts[0].replace('-', ' ').capitalize() if filtered_parts else \"Unknown\"\n",
    "\n",
    "#     # Remove unwanted words from city name\n",
    "#     for word in remove_words:\n",
    "#         city = city.replace(word, '')\n",
    "    \n",
    "\n",
    "#     return city.strip().capitalize()\n",
    "\n",
    "\n",
    "# # Scrape all comments from a paginated URL (e.g., https://example.com/comments?page=1), stop when no comments are found. So basically, this function scrapes all comments from all pages of a project\n",
    "# def scrape_all_comments(base_url):\n",
    "#     comments = []\n",
    "#     page = 1\n",
    "    \n",
    "#     # This while loop will continue until there are no comments on the page (extract_comments_from_page returns an empty list)\n",
    "#     while True:\n",
    "#         paginated_url = f\"{base_url}?page={page}\" if page > 1 else base_url\n",
    "#         response = requests.get(paginated_url)\n",
    "        \n",
    "#         if response.status_code != 200:\n",
    "#             print(f\"Failed to load page {page} for URL: {base_url}\")\n",
    "#             break\n",
    "        \n",
    "#         soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#         comments_on_page = extract_comments_from_page(soup)\n",
    "        \n",
    "#         if not comments_on_page:  # Stop if no comments on the page (extract_comments_from_page returns an empty list)\n",
    "#             break\n",
    "        \n",
    "#         # Extend the comments list with the comments from the current page and increment the page number\n",
    "#         comments.extend(comments_on_page)\n",
    "#         page += 1\n",
    "\n",
    "#     return comments\n",
    "\n",
    "# # Function to scrape the main content and comments for each URL \n",
    "# # This function is mainly used to scrape the main content and comments for all project URLs and call the scrape_all_comments function to get all comments for each project\n",
    "# # So usage scheme is: \n",
    "# # scrape_content_and_comments(to get main content and comments) -> scrape_all_comments(to get all comments for each project) \n",
    "# # -> extract_comments_from_page(to get comments from a single page) \n",
    "# # -> extract_city_name(to get city name from URL) \n",
    "# # -> form the final DataFrame with comments\n",
    "\n",
    "# def scrape_content_and_comments(urls):\n",
    "#     data = []\n",
    "    \n",
    "#     for url in urls:\n",
    "#         response = requests.get(url)\n",
    "#         if response.status_code != 200:\n",
    "#             print(f\"Failed to load URL: {url}\")\n",
    "#             continue\n",
    "        \n",
    "#         soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "#         # Scrape main content (title and description) by finding the 'title' tag and the 'div' tag with class 'flex-layout'\n",
    "#         title = soup.find('title').get_text(strip=True) if soup.find('title') else None\n",
    "#         content_div = soup.find('div', class_='flex-layout')\n",
    "#         content = content_div.get_text(strip=True) if content_div else None\n",
    "        \n",
    "#         # Scrape comments by calling the scrape_all_comments function\n",
    "#         comments = scrape_all_comments(url)\n",
    "        \n",
    "#         # Append the extracted information to the data list\n",
    "#         data.append({\n",
    "#             'URL': url,\n",
    "#             'Title': title,\n",
    "#             'Content': content,\n",
    "#             'Comments': comments\n",
    "#         })\n",
    "    \n",
    "#     return data\n",
    "\n",
    "# # Scrape comments for all project URLs from all_projects_df (created in the previous step)\n",
    "# urls = all_projects_df['Project URL'].tolist()  # Use the 'Project URL' column from all_projects_df\n",
    "# scraped_data = scrape_content_and_comments(urls)\n",
    "\n",
    "# # Create structured DataFrame for comments\n",
    "# comments_data = []\n",
    "\n",
    "# # Loop through the scraped data and extract comments, link them to the project URL and extract the city name\n",
    "# for item in scraped_data:\n",
    "#     for comment in item['Comments']:\n",
    "#         comment['URL'] = item['URL']  # Link comment to the project URL\n",
    "#         # Extract city name from URL\n",
    "#         city = extract_city_name(item['URL'])\n",
    "#         comment['City'] = city\n",
    "#         comments_data.append(comment)\n",
    "\n",
    "# # Create the comments DataFrame\n",
    "# df_comments = pd.DataFrame(comments_data)\n",
    "\n",
    "# # Create a mapping from URL to Project Title (mapping means that we can use the URL to get the Project Title)\n",
    "# url_to_title = all_projects_df.set_index('Project URL')['Project Title'].to_dict()\n",
    "\n",
    "# # Add a 'Project' column to df_comments using the mapping (again method map is working like that: it takes the URL and returns the Project Title)\n",
    "# df_comments['Project'] = df_comments['URL'].map(url_to_title)\n",
    "# df_comments = df_comments[['URL', 'Project', 'City'] + [col for col in df_comments.columns if col not in ['URL', 'Project', 'City']]]\n",
    "\n",
    "# # Save the comments DataFrame to a CSV file\n",
    "\n",
    "# df_comments.to_csv('data/all_comments.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments_df['Total Votes'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional cleaaning and structuring for Sieburg (review if it's needed) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# # Enhanced function to extract all logical parts, including \"Unterst√ºtzer*innen\"\n",
    "# def extract_full_data_with_supporters(content):\n",
    "#     # Extract title (everything before the first date)\n",
    "#     title_match = re.search(r'^(.*?)(\\r|\\d{1,2}\\.\\s\\w+\\s\\d{4})', content)\n",
    "#     title = title_match.group(1).strip() if title_match else None\n",
    "\n",
    "#     # Extract date\n",
    "#     date_match = re.search(r'\\d{1,2}\\.\\s\\w+\\s\\d{4}', content)\n",
    "#     date = date_match.group(0) if date_match else None\n",
    "\n",
    "#     # Extract comments count\n",
    "#     comments_match = re.search(r'(\\d+)\\sKommentare', content)\n",
    "#     comments = int(comments_match.group(1)) if comments_match else 0\n",
    "\n",
    "#     # Extract tags (sections with numbers or + signs)\n",
    "#     tags_match = re.findall(r'(\\d{1,2}[-+]\\d{1,2}|\\d{2}\\+)', content)\n",
    "#     tags = ', '.join(tags_match) if tags_match else None\n",
    "\n",
    "#     # Extract description (everything after \"Geselliges Beisammensein\" or similar patterns)\n",
    "#     description_start = re.search(r'(Geselliges Beisammensein|Angebotslandkarte)', content)\n",
    "#     description = content[description_start.start():].strip() if description_start else None\n",
    "\n",
    "#     # Extract username\n",
    "#     username_match = re.search(r'(\\w+\\s\\w+|Beigetreten am:.*?\\d{4})', content)\n",
    "#     username = username_match.group(1).split('Beigetreten am:')[0].strip() if username_match else None\n",
    "\n",
    "#     # Extract Vorschl√§ge count\n",
    "#     vorschlaege_match = re.search(r'Vorschl√§ge(\\d+)', content)\n",
    "#     vorschlaege = int(vorschlaege_match.group(1)) if vorschlaege_match else 0\n",
    "\n",
    "#     # Extract Konto verification status\n",
    "#     konto_match = re.search(r'(Konto\\s(verifiziert|ist nicht verifiziert))', content)\n",
    "#     konto_status = konto_match.group(2) if konto_match else None\n",
    "\n",
    "#     # # Extract registration date\n",
    "#     # registration_match = re.search(r'Beigetreten am:\\s(\\d{1,2}\\.\\s\\w+\\s\\d{4})', content)\n",
    "#     # registration_date = registration_match.group(1) if registration_match else None\n",
    "\n",
    "#     # Extract number of Unterst√ºtzer*innen\n",
    "#     supporters_match = re.search(r'(\\d+)\\sUnterst√ºtzer\\*in', content)\n",
    "#     supporters = int(supporters_match.group(1)) if supporters_match else 0\n",
    "\n",
    "#     return title, date, comments, tags, description, username, vorschlaege, konto_status, supporters\n",
    "\n",
    "# # Apply the enhanced function to the DataFrame and create new columns\n",
    "# df_sieburg[['Title', 'Date', 'Comments', 'Tags', 'Description', 'Username', 'Vorschl√§ge', 'Konto Status', 'Supporters']] = df_sieburg['Content'].apply(\n",
    "#     lambda x: pd.Series(extract_full_data_with_supporters(x))\n",
    "# )\n",
    "\n",
    "\n",
    "# # Function to clean description considering keywords, numeric patterns, and refined starting logic\n",
    "# def clean_description_advanced(content):\n",
    "#     # Define keywords that mark the beginning of the description\n",
    "#     keywords = [\n",
    "#         'Geselliges Beisammensein', 'Natur', 'Hilfe & Beratung', 'Bildung', \n",
    "#         'Musik', 'Bewegung', 'Glaube', 'Kulinarisches', 'Kunst & Kultur', 'Sonstiges',\n",
    "#     ]\n",
    "    \n",
    "#     # Check for keywords first\n",
    "#     for keyword in keywords:\n",
    "#         if keyword in content:\n",
    "#             start_idx = content.find(keyword) + len(keyword)\n",
    "#             description = content[start_idx:].strip()\n",
    "#             description = re.split(r'(Kommentare\\(.*?\\)|registrieren)', description)[0].strip()\n",
    "#             return description\n",
    "\n",
    "#     # If no keyword is found, check for numeric patterns like \"18-24, 25-49, etc.\"\n",
    "#     numeric_pattern = re.search(r'(\\d{1,2}[-+]\\d{1,2}|\\d{2}\\+)', content)\n",
    "#     if numeric_pattern:\n",
    "#         start_idx = numeric_pattern.end()\n",
    "#         description = content[start_idx:].strip()\n",
    "#         description = re.split(r'(Kommentare\\(.*?\\)|registrieren)', description)[0].strip()\n",
    "#         return description\n",
    "\n",
    "#     # As a fallback, find the first capital letter, quote, or digit to mark the start\n",
    "#     fallback_match = re.search(r'[A-Z\"0-9]', content)\n",
    "#     if fallback_match:\n",
    "#         start_idx = fallback_match.start()\n",
    "#         description = content[start_idx:].strip()\n",
    "#         description = re.split(r'(Kommentare\\(.*?\\)|registrieren)', description)[0].strip()\n",
    "#         return description\n",
    "\n",
    "#     # If nothing works, return the content as is\n",
    "#     return content\n",
    "\n",
    "# # Apply the advanced cleaning function to the Description column\n",
    "# df_sieburg['Description'] = df_sieburg['Content'].apply(clean_description_advanced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìÇ Load Dependencies & Data üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Loaded Successfully! Jena Comments: 314, Projects: 19, Proposals: 0\n"
     ]
    }
   ],
   "source": [
    "# üìå Import necessary libraries\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from fpdf import FPDF\n",
    "\n",
    "# üîë Set your Hugging Face API key\n",
    "HF_MODEL = \"tiiuae/falcon-7b-instruct\"  # Alternative: \"mistralai/Mistral-7B-Instruct\"\n",
    "\n",
    "# Load German NLP model\n",
    "nlp = spacy.load(\"de_core_news_sm\")  # Ensure this model is installed on your machine\n",
    "\n",
    "# üìå Load datasets\n",
    "comments_df = pd.read_csv(\"all_comments.csv\")\n",
    "projects_df = pd.read_csv(\"all_projects.csv\")\n",
    "proposals_df = pd.read_csv(\"all_proposals.csv\")\n",
    "\n",
    "# üìå Filter data for Jena\n",
    "jena_comments = comments_df[comments_df[\"City\"] == \"Jena\"].copy()\n",
    "jena_projects = projects_df[projects_df[\"City\"] == \"Jena\"].copy()\n",
    "jena_proposals = proposals_df[proposals_df[\"City\"] == \"Jena\"].copy()\n",
    "\n",
    "print(f\"‚úÖ Data Loaded Successfully! Jena Comments: {len(jena_comments)}, Projects: {len(jena_projects)}, Proposals: {len(jena_proposals)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Data Analysis & Insights üîç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Analysis Completed!\n",
      "\n",
      "Most Active Users:\n",
      " Username\n",
      "klaus.kleiner77     32\n",
      "PM                  18\n",
      "Klaus.kleiner77     16\n",
      "pfingstochse78      15\n",
      "Brabax              12\n",
      "Klaus.Kleiner       12\n",
      "Ronon               11\n",
      "Klaus.kleiner.77     8\n",
      "r_luen               7\n",
      "AnneK                6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Most Commented Projects:\n",
      " Project\n",
      "Stufe I - Kurzfristige Entwickelbarkeit           91\n",
      "Westbahnhofstra√üe                                 50\n",
      "Szenario 3 ‚Äûlangfristige Fl√§chenverf√ºgbarkeit‚Äú    50\n",
      "Stufe III ‚Äì Perspektivische Entwickelbarkeit      42\n",
      "Szenario 1 ‚ÄûKurzfristige Fl√§chenverf√ºgbarkeit‚Äú    32\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment Distribution:\n",
      " Sentiment Category\n",
      "Neutral     294\n",
      "Positive     18\n",
      "Negative      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Enhanced Insights Generated!\n",
      "üìå Most Discussed Topics (Top 10): [('Jena', 78), ('Stra√üenbahn', 75), ('Bahnhof', 69), ('Stadt', 55), ('finden', 53), ('Westbahnhof', 44), ('Gleis', 44), ('Planung', 43), ('Platz', 40), ('Stra√üe', 38)]\n",
      "\n",
      "üìå Most Liked Comment: Username                                                   PM\n",
      "Text        In diesem Szenario gef√§llt mir, dass kein (m.E...\n",
      "Likes                                                      16\n",
      "Name: 238, dtype: object\n",
      "\n",
      "üìå Most Controversial Comment: Username                                                             PM\n",
      "Text                  In diesem Szenario gef√§llt mir, dass kein (m.E...\n",
      "Likes                                                                16\n",
      "Dislikes                                                              0\n",
      "Like-Dislike Ratio                                                 16.0\n",
      "Name: 238, dtype: object\n",
      "\n",
      "üìÇ Insights saved as 'jena_insights.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rusel\\AppData\\Local\\Temp\\ipykernel_3240\\2274164406.py:98: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  insights_df = insights_df.applymap(clean_data)\n"
     ]
    }
   ],
   "source": [
    "# üîπ 1. Most Active Users\n",
    "most_active_users = jena_comments[\"Username\"].value_counts().head(10)\n",
    "\n",
    "# üîπ 2. Most Commented Projects\n",
    "most_commented_projects = jena_comments[\"Project\"].value_counts().head(5)\n",
    "\n",
    "# üîπ 3. Sentiment Analysis\n",
    "jena_comments.loc[:, \"Sentiment\"] = jena_comments[\"Text\"].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "jena_comments.loc[:, \"Sentiment Category\"] = jena_comments[\"Sentiment\"].apply(lambda x: \"Positive\" if x > 0 else (\"Negative\" if x < 0 else \"Neutral\"))\n",
    "sentiment_counts = jena_comments[\"Sentiment Category\"].value_counts()\n",
    "\n",
    "print(\"‚úÖ Data Analysis Completed!\")\n",
    "print(\"\\nMost Active Users:\\n\", most_active_users)\n",
    "print(\"\\nMost Commented Projects:\\n\", most_commented_projects)\n",
    "print(\"\\nSentiment Distribution:\\n\", sentiment_counts)\n",
    "\n",
    "# üîπ 1. Most Discussed Topics Using spaCy (More accurate German processing)\n",
    "def extract_keywords(text):\n",
    "    doc = nlp(str(text))\n",
    "    keywords = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "    return keywords\n",
    "\n",
    "jena_comments[\"Keywords\"] = jena_comments[\"Text\"].apply(extract_keywords)\n",
    "all_keywords = [keyword for keywords in jena_comments[\"Keywords\"] for keyword in keywords]\n",
    "keyword_counts = Counter(all_keywords).most_common(20)\n",
    "\n",
    "# üîπ 2. Most Upvoted & Downvoted Comments\n",
    "most_liked_comments = jena_comments.nlargest(10, \"Likes\")[[\"Username\", \"Text\", \"Likes\"]]\n",
    "most_disliked_comments = jena_comments.nlargest(10, \"Dislikes\")[[\"Username\", \"Text\", \"Dislikes\"]]\n",
    "\n",
    "# üîπ 3. Peak Commenting Time (Hourly & Daily Trends)\n",
    "jena_comments[\"Date\"] = pd.to_datetime(jena_comments[\"Date\"], errors=\"coerce\")\n",
    "jena_comments[\"Hour\"] = jena_comments[\"Date\"].dt.hour\n",
    "jena_comments[\"Day\"] = jena_comments[\"Date\"].dt.dayofweek\n",
    "\n",
    "hourly_distribution = jena_comments[\"Hour\"].value_counts().sort_index()\n",
    "daily_distribution = jena_comments[\"Day\"].value_counts().sort_index()\n",
    "\n",
    "# üîπ 5. Most Supported Proposals\n",
    "most_supported_proposals = proposals_df.nlargest(10, \"Supporters\")[[\"Title\", \"Supporters\", \"City\"]]\n",
    "\n",
    "# üîπ 6. Projects with the Most Proposals\n",
    "most_proposals_per_project = projects_df.nlargest(10, \"Proposal Count\")[[\"Project Title\", \"Proposal Count\", \"City\"]]\n",
    "\n",
    "# üîπ 7. Most Controversial Topics (High disagreement: likes vs. dislikes ratio)\n",
    "jena_comments[\"Like-Dislike Ratio\"] = jena_comments[\"Likes\"] / (jena_comments[\"Dislikes\"] + 1)\n",
    "most_controversial_comments = jena_comments.nlargest(10, \"Like-Dislike Ratio\")[[\"Username\", \"Text\", \"Likes\", \"Dislikes\", \"Like-Dislike Ratio\"]]\n",
    "\n",
    "# üîπ 8. Users with the Most Repeated Engagement (Users commenting on multiple projects)\n",
    "user_project_counts = jena_comments.groupby(\"Username\")[\"Project\"].nunique().sort_values(ascending=False).head(10)\n",
    "\n",
    "# üîπ 10. Average Engagement Per Project (Number of comments per project)\n",
    "average_comments_per_project = jena_comments.groupby(\"Project\").size().mean()\n",
    "\n",
    "# üîπ Display Insights\n",
    "insights = {\n",
    "    \"Most Discussed Topics\": keyword_counts,\n",
    "    \"Most Liked Comments\": most_liked_comments.to_dict(orient=\"records\"),\n",
    "    \"Most Disliked Comments\": most_disliked_comments.to_dict(orient=\"records\"),\n",
    "    \"Peak Commenting Hours\": hourly_distribution.to_dict(),\n",
    "    \"Peak Commenting Days\": daily_distribution.to_dict(),\n",
    "    \"Most Supported Proposals\": most_supported_proposals.to_dict(orient=\"records\"),\n",
    "    \"Projects with Most Proposals\": most_proposals_per_project.to_dict(orient=\"records\"),\n",
    "    \"Most Controversial Comments\": most_controversial_comments.to_dict(orient=\"records\"),\n",
    "    \"Users with Most Repeated Engagement\": user_project_counts.to_dict(),\n",
    "    \"Average Comments Per Project\": [average_comments_per_project]  # Convert float to list\n",
    "}\n",
    "\n",
    "# Print key insights\n",
    "print(\"\\n‚úÖ Enhanced Insights Generated!\")\n",
    "print(\"üìå Most Discussed Topics (Top 10):\", keyword_counts[:10])\n",
    "print(\"\\nüìå Most Liked Comment:\", most_liked_comments.iloc[0] if not most_liked_comments.empty else \"No data\")\n",
    "print(\"\\nüìå Most Controversial Comment:\", most_controversial_comments.iloc[0] if not most_controversial_comments.empty else \"No data\")\n",
    "\n",
    "# Save insights as a CSV file\n",
    "insights_df = pd.DataFrame.from_dict(insights, orient='index')\n",
    "insights_df.to_csv(\"jena_insights.csv\")\n",
    "\n",
    "print(\"\\nüìÇ Insights saved as 'jena_insights.csv'\")\n",
    "\n",
    "import ast  # To safely evaluate strings as Python objects\n",
    "\n",
    "# Function to clean and convert stringified data\n",
    "def clean_data(value):\n",
    "    if pd.isna(value) or value == \"nan\":\n",
    "        return \"Keine Daten verf√ºgbar\"  # German for \"No data available\"\n",
    "    try:\n",
    "        parsed_value = ast.literal_eval(value)  # Convert string to tuple/dict if applicable\n",
    "        if isinstance(parsed_value, tuple):\n",
    "            return f\"{parsed_value[0]} ({parsed_value[1]})\"  # Format tuple nicely\n",
    "        elif isinstance(parsed_value, dict):\n",
    "            return f\"{parsed_value.get('Username', 'Unknown')}: {parsed_value.get('Text', '')}\"\n",
    "        return str(parsed_value)  # Convert any other format to string\n",
    "    except (ValueError, SyntaxError):\n",
    "        return str(value)  # Return as-is if it can't be parsed\n",
    "\n",
    "# Apply cleaning function to all values in the DataFrame\n",
    "insights_df = insights_df.applymap(clean_data)\n",
    "\n",
    "# Drop columns with too many missing values (threshold: 80% empty)\n",
    "insights_df.dropna(axis=1, thresh=int(len(insights_df) * 0.2), inplace=True)\n",
    "\n",
    "# Convert dataframe to readable string format\n",
    "insights_summary = insights_df.to_string(index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Most Discussed Topics</th>\n",
       "      <td>('Jena', 78)</td>\n",
       "      <td>('Stra√üenbahn', 75)</td>\n",
       "      <td>('Bahnhof', 69)</td>\n",
       "      <td>('Stadt', 55)</td>\n",
       "      <td>('finden', 53)</td>\n",
       "      <td>('Westbahnhof', 44)</td>\n",
       "      <td>('Gleis', 44)</td>\n",
       "      <td>('Planung', 43)</td>\n",
       "      <td>('Platz', 40)</td>\n",
       "      <td>('Stra√üe', 38)</td>\n",
       "      <td>('Unterf√ºhrung', 35)</td>\n",
       "      <td>('direkt', 34)</td>\n",
       "      <td>('Richtung', 33)</td>\n",
       "      <td>('Szenario', 33)</td>\n",
       "      <td>('Br√ºcke', 32)</td>\n",
       "      <td>('Haltestelle', 31)</td>\n",
       "      <td>('sehen', 31)</td>\n",
       "      <td>('Rahmenplan', 31)</td>\n",
       "      <td>('Radfahrer', 30)</td>\n",
       "      <td>('fahren', 29)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Most Liked Comments</th>\n",
       "      <td>{'Username': 'PM', 'Text': 'In diesem Szenario...</td>\n",
       "      <td>{'Username': 'PM', 'Text': 'Wenn Umbau, dann r...</td>\n",
       "      <td>{'Username': 'PM', 'Text': 'Die Aufweitung und...</td>\n",
       "      <td>{'Username': 'PM', 'Text': 'Die Br√ºcke muss la...</td>\n",
       "      <td>{'Username': 'r_luen', 'Text': '1. Zuerst einm...</td>\n",
       "      <td>{'Username': 'AnneK', 'Text': 'Dem ist absolut...</td>\n",
       "      <td>{'Username': 'r_luen', 'Text': 'Ich kann nicht...</td>\n",
       "      <td>{'Username': 'Brabax', 'Text': 'Der Neubau der...</td>\n",
       "      <td>{'Username': 'Patzak', 'Text': 'Wenn man schon...</td>\n",
       "      <td>{'Username': 'r_luen', 'Text': 'F√ºr eine zukun...</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Most Disliked Comments</th>\n",
       "      <td>{'Username': 'klaus.kleiner3', 'Text': 'Die Pl...</td>\n",
       "      <td>{'Username': 'Dominique', 'Text': 'Den zus√§tzl...</td>\n",
       "      <td>{'Username': 'klaus.kleiner3', 'Text': 'Ich ha...</td>\n",
       "      <td>{'Username': 'Astrid Lindner', 'Text': 'Ich bi...</td>\n",
       "      <td>{'Username': 'klaus.kleiner77', 'Text': 'Also ...</td>\n",
       "      <td>{'Username': 'klaus.kleiner77', 'Text': 'Wie w...</td>\n",
       "      <td>{'Username': 'klaus.kleiner', 'Text': '@PMGut,...</td>\n",
       "      <td>{'Username': 'klaus.kleiner', 'Text': '@PMGut,...</td>\n",
       "      <td>{'Username': 'Bastian', 'Text': 'Ich kann mir ...</td>\n",
       "      <td>{'Username': 'pfingstochse78', 'Text': 'Wenn d...</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peak Commenting Hours</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peak Commenting Days</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Most Supported Proposals</th>\n",
       "      <td>{'Title': 'Kulturelle Belebung durch Tanzfl√§ch...</td>\n",
       "      <td>{'Title': 'Ich bin mit Variante 2 zufrieden.',...</td>\n",
       "      <td>{'Title': 'Besuche des B√ºrgerb√ºros √ºberfl√ºssig...</td>\n",
       "      <td>{'Title': 'Wolkenstimmung √ºber der Luitpoldh√∂h...</td>\n",
       "      <td>{'Title': 'Luftaufnahme Luitpoldh√∂he', 'Suppor...</td>\n",
       "      <td>{'Title': 'Ich bin mit Variante 1 zufrieden.',...</td>\n",
       "      <td>{'Title': 'Digital optimierte Nutzung privater...</td>\n",
       "      <td>{'Title': 'Spielplatz 2', 'Supporters': 50.0, ...</td>\n",
       "      <td>{'Title': 'Spielplatz 1', 'Supporters': 47.0, ...</td>\n",
       "      <td>{'Title': 'Spielplatz in der Luitpoldh√∂he', 'S...</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Projects with Most Proposals</th>\n",
       "      <td>{'Project Title': 'Zukunftskonzepte f√ºr die In...</td>\n",
       "      <td>{'Project Title': 'Angebotslandkarte', 'Propos...</td>\n",
       "      <td>{'Project Title': 'Verkehrskonzept Hauptstra√üe...</td>\n",
       "      <td>{'Project Title': 'Verkehrsentwicklungsplan', ...</td>\n",
       "      <td>{'Project Title': 'MoveRegioM', 'Proposal Coun...</td>\n",
       "      <td>{'Project Title': 'Standortvorschl√§ge', 'Propo...</td>\n",
       "      <td>{'Project Title': 'Digitalisierung im M√ºnchner...</td>\n",
       "      <td>{'Project Title': 'Der neue Ilzer Land-Anh√§nge...</td>\n",
       "      <td>{'Project Title': 'Energiesparen', 'Proposal C...</td>\n",
       "      <td>{'Project Title': 'Spielpl√§tze Halde Nord', 'P...</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Most Controversial Comments</th>\n",
       "      <td>{'Username': 'PM', 'Text': 'In diesem Szenario...</td>\n",
       "      <td>{'Username': 'PM', 'Text': 'Wenn Umbau, dann r...</td>\n",
       "      <td>{'Username': 'PM', 'Text': 'Die Aufweitung und...</td>\n",
       "      <td>{'Username': 'PM', 'Text': 'Die Br√ºcke muss la...</td>\n",
       "      <td>{'Username': 'r_luen', 'Text': 'Ich kann nicht...</td>\n",
       "      <td>{'Username': 'Brabax', 'Text': 'Der Neubau der...</td>\n",
       "      <td>{'Username': 'r_luen', 'Text': 'F√ºr eine zukun...</td>\n",
       "      <td>{'Username': 'pfingstochse78', 'Text': 'Ich ma...</td>\n",
       "      <td>{'Username': 'PM', 'Text': 'Der Rahmenplan hat...</td>\n",
       "      <td>{'Username': 'Radfahrergast', 'Text': 'Gemeins...</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Users with Most Repeated Engagement</th>\n",
       "      <td>Brabax</td>\n",
       "      <td>JoSch</td>\n",
       "      <td>pfingstochse78</td>\n",
       "      <td>PM</td>\n",
       "      <td>Stig Ludwig</td>\n",
       "      <td>JessicaR</td>\n",
       "      <td>Daniela K√∂hler</td>\n",
       "      <td>Mr.Moto</td>\n",
       "      <td>Inga Gl√∂kler</td>\n",
       "      <td>Patzak</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Comments Per Project</th>\n",
       "      <td>44.857142857142854</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "      <td>Keine Daten verf√ºgbar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    0   \\\n",
       "Most Discussed Topics                                                     ('Jena', 78)   \n",
       "Most Liked Comments                  {'Username': 'PM', 'Text': 'In diesem Szenario...   \n",
       "Most Disliked Comments               {'Username': 'klaus.kleiner3', 'Text': 'Die Pl...   \n",
       "Peak Commenting Hours                                                              0.0   \n",
       "Peak Commenting Days                                                               0.0   \n",
       "Most Supported Proposals             {'Title': 'Kulturelle Belebung durch Tanzfl√§ch...   \n",
       "Projects with Most Proposals         {'Project Title': 'Zukunftskonzepte f√ºr die In...   \n",
       "Most Controversial Comments          {'Username': 'PM', 'Text': 'In diesem Szenario...   \n",
       "Users with Most Repeated Engagement                                             Brabax   \n",
       "Average Comments Per Project                                        44.857142857142854   \n",
       "\n",
       "                                                                                    1   \\\n",
       "Most Discussed Topics                                              ('Stra√üenbahn', 75)   \n",
       "Most Liked Comments                  {'Username': 'PM', 'Text': 'Wenn Umbau, dann r...   \n",
       "Most Disliked Comments               {'Username': 'Dominique', 'Text': 'Den zus√§tzl...   \n",
       "Peak Commenting Hours                                                              5.0   \n",
       "Peak Commenting Days                                                               1.0   \n",
       "Most Supported Proposals             {'Title': 'Ich bin mit Variante 2 zufrieden.',...   \n",
       "Projects with Most Proposals         {'Project Title': 'Angebotslandkarte', 'Propos...   \n",
       "Most Controversial Comments          {'Username': 'PM', 'Text': 'Wenn Umbau, dann r...   \n",
       "Users with Most Repeated Engagement                                              JoSch   \n",
       "Average Comments Per Project                                     Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                                                    2   \\\n",
       "Most Discussed Topics                                                  ('Bahnhof', 69)   \n",
       "Most Liked Comments                  {'Username': 'PM', 'Text': 'Die Aufweitung und...   \n",
       "Most Disliked Comments               {'Username': 'klaus.kleiner3', 'Text': 'Ich ha...   \n",
       "Peak Commenting Hours                                                              6.0   \n",
       "Peak Commenting Days                                                               2.0   \n",
       "Most Supported Proposals             {'Title': 'Besuche des B√ºrgerb√ºros √ºberfl√ºssig...   \n",
       "Projects with Most Proposals         {'Project Title': 'Verkehrskonzept Hauptstra√üe...   \n",
       "Most Controversial Comments          {'Username': 'PM', 'Text': 'Die Aufweitung und...   \n",
       "Users with Most Repeated Engagement                                     pfingstochse78   \n",
       "Average Comments Per Project                                     Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                                                    3   \\\n",
       "Most Discussed Topics                                                    ('Stadt', 55)   \n",
       "Most Liked Comments                  {'Username': 'PM', 'Text': 'Die Br√ºcke muss la...   \n",
       "Most Disliked Comments               {'Username': 'Astrid Lindner', 'Text': 'Ich bi...   \n",
       "Peak Commenting Hours                                                              7.0   \n",
       "Peak Commenting Days                                                               3.0   \n",
       "Most Supported Proposals             {'Title': 'Wolkenstimmung √ºber der Luitpoldh√∂h...   \n",
       "Projects with Most Proposals         {'Project Title': 'Verkehrsentwicklungsplan', ...   \n",
       "Most Controversial Comments          {'Username': 'PM', 'Text': 'Die Br√ºcke muss la...   \n",
       "Users with Most Repeated Engagement                                                 PM   \n",
       "Average Comments Per Project                                     Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                                                    4   \\\n",
       "Most Discussed Topics                                                   ('finden', 53)   \n",
       "Most Liked Comments                  {'Username': 'r_luen', 'Text': '1. Zuerst einm...   \n",
       "Most Disliked Comments               {'Username': 'klaus.kleiner77', 'Text': 'Also ...   \n",
       "Peak Commenting Hours                                                              9.0   \n",
       "Peak Commenting Days                                                               4.0   \n",
       "Most Supported Proposals             {'Title': 'Luftaufnahme Luitpoldh√∂he', 'Suppor...   \n",
       "Projects with Most Proposals         {'Project Title': 'MoveRegioM', 'Proposal Coun...   \n",
       "Most Controversial Comments          {'Username': 'r_luen', 'Text': 'Ich kann nicht...   \n",
       "Users with Most Repeated Engagement                                        Stig Ludwig   \n",
       "Average Comments Per Project                                     Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                                                    5   \\\n",
       "Most Discussed Topics                                              ('Westbahnhof', 44)   \n",
       "Most Liked Comments                  {'Username': 'AnneK', 'Text': 'Dem ist absolut...   \n",
       "Most Disliked Comments               {'Username': 'klaus.kleiner77', 'Text': 'Wie w...   \n",
       "Peak Commenting Hours                                                             10.0   \n",
       "Peak Commenting Days                                                               5.0   \n",
       "Most Supported Proposals             {'Title': 'Ich bin mit Variante 1 zufrieden.',...   \n",
       "Projects with Most Proposals         {'Project Title': 'Standortvorschl√§ge', 'Propo...   \n",
       "Most Controversial Comments          {'Username': 'Brabax', 'Text': 'Der Neubau der...   \n",
       "Users with Most Repeated Engagement                                           JessicaR   \n",
       "Average Comments Per Project                                     Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                                                    6   \\\n",
       "Most Discussed Topics                                                    ('Gleis', 44)   \n",
       "Most Liked Comments                  {'Username': 'r_luen', 'Text': 'Ich kann nicht...   \n",
       "Most Disliked Comments               {'Username': 'klaus.kleiner', 'Text': '@PMGut,...   \n",
       "Peak Commenting Hours                                                             11.0   \n",
       "Peak Commenting Days                                                               6.0   \n",
       "Most Supported Proposals             {'Title': 'Digital optimierte Nutzung privater...   \n",
       "Projects with Most Proposals         {'Project Title': 'Digitalisierung im M√ºnchner...   \n",
       "Most Controversial Comments          {'Username': 'r_luen', 'Text': 'F√ºr eine zukun...   \n",
       "Users with Most Repeated Engagement                                     Daniela K√∂hler   \n",
       "Average Comments Per Project                                     Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                                                    7   \\\n",
       "Most Discussed Topics                                                  ('Planung', 43)   \n",
       "Most Liked Comments                  {'Username': 'Brabax', 'Text': 'Der Neubau der...   \n",
       "Most Disliked Comments               {'Username': 'klaus.kleiner', 'Text': '@PMGut,...   \n",
       "Peak Commenting Hours                                                             12.0   \n",
       "Peak Commenting Days                                             Keine Daten verf√ºgbar   \n",
       "Most Supported Proposals             {'Title': 'Spielplatz 2', 'Supporters': 50.0, ...   \n",
       "Projects with Most Proposals         {'Project Title': 'Der neue Ilzer Land-Anh√§nge...   \n",
       "Most Controversial Comments          {'Username': 'pfingstochse78', 'Text': 'Ich ma...   \n",
       "Users with Most Repeated Engagement                                            Mr.Moto   \n",
       "Average Comments Per Project                                     Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                                                    8   \\\n",
       "Most Discussed Topics                                                    ('Platz', 40)   \n",
       "Most Liked Comments                  {'Username': 'Patzak', 'Text': 'Wenn man schon...   \n",
       "Most Disliked Comments               {'Username': 'Bastian', 'Text': 'Ich kann mir ...   \n",
       "Peak Commenting Hours                                                             14.0   \n",
       "Peak Commenting Days                                             Keine Daten verf√ºgbar   \n",
       "Most Supported Proposals             {'Title': 'Spielplatz 1', 'Supporters': 47.0, ...   \n",
       "Projects with Most Proposals         {'Project Title': 'Energiesparen', 'Proposal C...   \n",
       "Most Controversial Comments          {'Username': 'PM', 'Text': 'Der Rahmenplan hat...   \n",
       "Users with Most Repeated Engagement                                       Inga Gl√∂kler   \n",
       "Average Comments Per Project                                     Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                                                    9   \\\n",
       "Most Discussed Topics                                                   ('Stra√üe', 38)   \n",
       "Most Liked Comments                  {'Username': 'r_luen', 'Text': 'F√ºr eine zukun...   \n",
       "Most Disliked Comments               {'Username': 'pfingstochse78', 'Text': 'Wenn d...   \n",
       "Peak Commenting Hours                                                             15.0   \n",
       "Peak Commenting Days                                             Keine Daten verf√ºgbar   \n",
       "Most Supported Proposals             {'Title': 'Spielplatz in der Luitpoldh√∂he', 'S...   \n",
       "Projects with Most Proposals         {'Project Title': 'Spielpl√§tze Halde Nord', 'P...   \n",
       "Most Controversial Comments          {'Username': 'Radfahrergast', 'Text': 'Gemeins...   \n",
       "Users with Most Repeated Engagement                                             Patzak   \n",
       "Average Comments Per Project                                     Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                        10  \\\n",
       "Most Discussed Topics                 ('Unterf√ºhrung', 35)   \n",
       "Most Liked Comments                  Keine Daten verf√ºgbar   \n",
       "Most Disliked Comments               Keine Daten verf√ºgbar   \n",
       "Peak Commenting Hours                                 16.0   \n",
       "Peak Commenting Days                 Keine Daten verf√ºgbar   \n",
       "Most Supported Proposals             Keine Daten verf√ºgbar   \n",
       "Projects with Most Proposals         Keine Daten verf√ºgbar   \n",
       "Most Controversial Comments          Keine Daten verf√ºgbar   \n",
       "Users with Most Repeated Engagement  Keine Daten verf√ºgbar   \n",
       "Average Comments Per Project         Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                        11  \\\n",
       "Most Discussed Topics                       ('direkt', 34)   \n",
       "Most Liked Comments                  Keine Daten verf√ºgbar   \n",
       "Most Disliked Comments               Keine Daten verf√ºgbar   \n",
       "Peak Commenting Hours                                 17.0   \n",
       "Peak Commenting Days                 Keine Daten verf√ºgbar   \n",
       "Most Supported Proposals             Keine Daten verf√ºgbar   \n",
       "Projects with Most Proposals         Keine Daten verf√ºgbar   \n",
       "Most Controversial Comments          Keine Daten verf√ºgbar   \n",
       "Users with Most Repeated Engagement  Keine Daten verf√ºgbar   \n",
       "Average Comments Per Project         Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                        12  \\\n",
       "Most Discussed Topics                     ('Richtung', 33)   \n",
       "Most Liked Comments                  Keine Daten verf√ºgbar   \n",
       "Most Disliked Comments               Keine Daten verf√ºgbar   \n",
       "Peak Commenting Hours                                 18.0   \n",
       "Peak Commenting Days                 Keine Daten verf√ºgbar   \n",
       "Most Supported Proposals             Keine Daten verf√ºgbar   \n",
       "Projects with Most Proposals         Keine Daten verf√ºgbar   \n",
       "Most Controversial Comments          Keine Daten verf√ºgbar   \n",
       "Users with Most Repeated Engagement  Keine Daten verf√ºgbar   \n",
       "Average Comments Per Project         Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                        13  \\\n",
       "Most Discussed Topics                     ('Szenario', 33)   \n",
       "Most Liked Comments                  Keine Daten verf√ºgbar   \n",
       "Most Disliked Comments               Keine Daten verf√ºgbar   \n",
       "Peak Commenting Hours                                 19.0   \n",
       "Peak Commenting Days                 Keine Daten verf√ºgbar   \n",
       "Most Supported Proposals             Keine Daten verf√ºgbar   \n",
       "Projects with Most Proposals         Keine Daten verf√ºgbar   \n",
       "Most Controversial Comments          Keine Daten verf√ºgbar   \n",
       "Users with Most Repeated Engagement  Keine Daten verf√ºgbar   \n",
       "Average Comments Per Project         Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                        14  \\\n",
       "Most Discussed Topics                       ('Br√ºcke', 32)   \n",
       "Most Liked Comments                  Keine Daten verf√ºgbar   \n",
       "Most Disliked Comments               Keine Daten verf√ºgbar   \n",
       "Peak Commenting Hours                                 20.0   \n",
       "Peak Commenting Days                 Keine Daten verf√ºgbar   \n",
       "Most Supported Proposals             Keine Daten verf√ºgbar   \n",
       "Projects with Most Proposals         Keine Daten verf√ºgbar   \n",
       "Most Controversial Comments          Keine Daten verf√ºgbar   \n",
       "Users with Most Repeated Engagement  Keine Daten verf√ºgbar   \n",
       "Average Comments Per Project         Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                        15  \\\n",
       "Most Discussed Topics                  ('Haltestelle', 31)   \n",
       "Most Liked Comments                  Keine Daten verf√ºgbar   \n",
       "Most Disliked Comments               Keine Daten verf√ºgbar   \n",
       "Peak Commenting Hours                                 21.0   \n",
       "Peak Commenting Days                 Keine Daten verf√ºgbar   \n",
       "Most Supported Proposals             Keine Daten verf√ºgbar   \n",
       "Projects with Most Proposals         Keine Daten verf√ºgbar   \n",
       "Most Controversial Comments          Keine Daten verf√ºgbar   \n",
       "Users with Most Repeated Engagement  Keine Daten verf√ºgbar   \n",
       "Average Comments Per Project         Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                        16  \\\n",
       "Most Discussed Topics                        ('sehen', 31)   \n",
       "Most Liked Comments                  Keine Daten verf√ºgbar   \n",
       "Most Disliked Comments               Keine Daten verf√ºgbar   \n",
       "Peak Commenting Hours                                 22.0   \n",
       "Peak Commenting Days                 Keine Daten verf√ºgbar   \n",
       "Most Supported Proposals             Keine Daten verf√ºgbar   \n",
       "Projects with Most Proposals         Keine Daten verf√ºgbar   \n",
       "Most Controversial Comments          Keine Daten verf√ºgbar   \n",
       "Users with Most Repeated Engagement  Keine Daten verf√ºgbar   \n",
       "Average Comments Per Project         Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                        17  \\\n",
       "Most Discussed Topics                   ('Rahmenplan', 31)   \n",
       "Most Liked Comments                  Keine Daten verf√ºgbar   \n",
       "Most Disliked Comments               Keine Daten verf√ºgbar   \n",
       "Peak Commenting Hours                                 23.0   \n",
       "Peak Commenting Days                 Keine Daten verf√ºgbar   \n",
       "Most Supported Proposals             Keine Daten verf√ºgbar   \n",
       "Projects with Most Proposals         Keine Daten verf√ºgbar   \n",
       "Most Controversial Comments          Keine Daten verf√ºgbar   \n",
       "Users with Most Repeated Engagement  Keine Daten verf√ºgbar   \n",
       "Average Comments Per Project         Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                        18  \\\n",
       "Most Discussed Topics                    ('Radfahrer', 30)   \n",
       "Most Liked Comments                  Keine Daten verf√ºgbar   \n",
       "Most Disliked Comments               Keine Daten verf√ºgbar   \n",
       "Peak Commenting Hours                Keine Daten verf√ºgbar   \n",
       "Peak Commenting Days                 Keine Daten verf√ºgbar   \n",
       "Most Supported Proposals             Keine Daten verf√ºgbar   \n",
       "Projects with Most Proposals         Keine Daten verf√ºgbar   \n",
       "Most Controversial Comments          Keine Daten verf√ºgbar   \n",
       "Users with Most Repeated Engagement  Keine Daten verf√ºgbar   \n",
       "Average Comments Per Project         Keine Daten verf√ºgbar   \n",
       "\n",
       "                                                        19  \n",
       "Most Discussed Topics                       ('fahren', 29)  \n",
       "Most Liked Comments                  Keine Daten verf√ºgbar  \n",
       "Most Disliked Comments               Keine Daten verf√ºgbar  \n",
       "Peak Commenting Hours                Keine Daten verf√ºgbar  \n",
       "Peak Commenting Days                 Keine Daten verf√ºgbar  \n",
       "Most Supported Proposals             Keine Daten verf√ºgbar  \n",
       "Projects with Most Proposals         Keine Daten verf√ºgbar  \n",
       "Most Controversial Comments          Keine Daten verf√ºgbar  \n",
       "Users with Most Repeated Engagement  Keine Daten verf√ºgbar  \n",
       "Average Comments Per Project         Keine Daten verf√ºgbar  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insights_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† NLP Processing & Word Cloud ‚òÅÔ∏è\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NLP Analysis & Visualizations Completed!\n",
      "\n",
      "Top Discussion Topics:\n",
      " [('Jena', 78), ('Stra√üenbahn', 75), ('Bahnhof', 69), ('Stadt', 55), ('finden', 53), ('Westbahnhof', 44), ('Gleis', 44), ('Planung', 43), ('Platz', 40), ('Stra√üe', 38), ('Unterf√ºhrung', 35), ('direkt', 34), ('Richtung', 33), ('Szenario', 33), ('Br√ºcke', 32), ('Haltestelle', 31), ('sehen', 31), ('Rahmenplan', 31), ('Radfahrer', 30), ('fahren', 29)]\n"
     ]
    }
   ],
   "source": [
    "# üîπ 4. NLP Analysis with spaCy (Topic Extraction)\n",
    "def extract_keywords(text):\n",
    "    doc = nlp(str(text))\n",
    "    keywords = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]\n",
    "    return keywords\n",
    "\n",
    "jena_comments.loc[:, \"Keywords\"] = jena_comments[\"Text\"].apply(extract_keywords)\n",
    "all_keywords = [keyword for keywords in jena_comments[\"Keywords\"] for keyword in keywords]\n",
    "keyword_counts = Counter(all_keywords).most_common(20)\n",
    "\n",
    "# üîπ 5. Generate Word Cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(all_keywords))\n",
    "wordcloud_path = \"jena_wordcloud.png\"\n",
    "wordcloud.to_file(wordcloud_path)\n",
    "\n",
    "# üîπ 6. Generate Activity Charts\n",
    "plt.figure(figsize=(8, 5))\n",
    "most_active_users.plot(kind=\"bar\", color=\"blue\")\n",
    "plt.title(\"Top 10 Most Active Users in Jena\")\n",
    "plt.xlabel(\"Username\")\n",
    "plt.ylabel(\"Number of Comments\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "active_users_plot_path = \"jena_active_users.png\"\n",
    "plt.savefig(active_users_plot_path)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sentiment_counts.plot(kind=\"bar\", color=[\"green\", \"gray\", \"red\"])\n",
    "plt.title(\"Sentiment Distribution of Comments in Jena\")\n",
    "plt.xlabel(\"Sentiment Category\")\n",
    "plt.ylabel(\"Number of Comments\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "sentiment_plot_path = \"jena_sentiment_distribution.png\"\n",
    "plt.savefig(sentiment_plot_path)\n",
    "plt.close()\n",
    "\n",
    "print(\"‚úÖ NLP Analysis & Visualizations Completed!\")\n",
    "print(\"\\nTop Discussion Topics:\\n\", keyword_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ AI-Powered Summary üìù\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ AI Summary Generated!\n",
      "Generate a structured analytical report on civic engagement in Jena based on the following insights:\n",
      "\n",
      "\n",
      "City: Jena\n",
      "Total Projects: 19\n",
      "Total Proposals: 0\n",
      "Total Comments: 314\n",
      "\n",
      "Top 5 Most Commented Projects:\n",
      "Project\n",
      "Stufe I - Kurzfristige Entwickelbarkeit           91\n",
      "Westbahnhofstra√üe                                 50\n",
      "Szenario 3 ‚Äûlangfristige Fl√§chenverf√ºgbarkeit‚Äú    50\n",
      "Stufe III ‚Äì Perspektivische Entwickelbarkeit      42\n",
      "Szenario 1 ‚ÄûKurzfristige Fl√§chenverf√ºgbarkeit‚Äú    32\n",
      "\n",
      "Top 10 Most Active Use\n"
     ]
    }
   ],
   "source": [
    "# üîπ 7. Generate AI-Powered Summary via Hugging Face API\n",
    "jena_data_summary = f\"\"\"\n",
    "City: Jena\n",
    "Total Projects: {len(jena_projects)}\n",
    "Total Proposals: {len(jena_proposals)}\n",
    "Total Comments: {len(jena_comments)}\n",
    "\n",
    "Top 5 Most Commented Projects:\n",
    "{most_commented_projects.to_string()}\n",
    "\n",
    "Top 10 Most Active Users:\n",
    "{most_active_users.to_string()}\n",
    "\n",
    "Sentiment Analysis:\n",
    "- Neutral Comments: {sentiment_counts.get('Neutral', 0)}\n",
    "- Positive Comments: {sentiment_counts.get('Positive', 0)}\n",
    "- Negative Comments: {sentiment_counts.get('Negative', 0)}\n",
    "\n",
    "Most Common Discussion Topics:\n",
    "{', '.join([word for word, count in keyword_counts])}\n",
    "\"\"\"\n",
    "\n",
    "ai_prompt = f\"\"\"\n",
    "Generate a structured analytical report on civic engagement in Jena based on the following insights:\n",
    "\n",
    "{jena_data_summary}\n",
    "\n",
    "The report should include:\n",
    "- A professional introduction about civic engagement in Jena.\n",
    "- Key trends and insights from the provided data.\n",
    "- Observations on public sentiment and discussion topics.\n",
    "- Suggestions for improving citizen engagement.\n",
    "\n",
    "Ensure the report is structured, formal, and insightful.\n",
    "\"\"\"\n",
    "\n",
    "def generate_report(text):\n",
    "    payload = {\"inputs\": text, \"parameters\": {\"max_new_tokens\": 1000}}\n",
    "\n",
    "    \n",
    "    try:\n",
    "        result = response.json()\n",
    "        if \"error\" in result:\n",
    "            return f\"‚ùå Error from Hugging Face API: {result['error']}\"\n",
    "        elif isinstance(result, list) and \"generated_text\" in result[0]:\n",
    "            return result[0][\"generated_text\"]\n",
    "        else:\n",
    "            return \"‚ùå Unexpected API response format.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Exception occurred: {str(e)}\"\n",
    "\n",
    "# Call AI for Summary\n",
    "# Call AI for Summary (Ensure unique output)\n",
    "ai_generated_report = generate_report(ai_prompt).strip()\n",
    "\n",
    "# Print only key insights from the AI-generated content\n",
    "print(\"\\n‚úÖ AI Summary Generated!\")\n",
    "print(ai_generated_report[:500])  # Print only first 500 characters for preview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìÑ Generate AI-Powered PDF Report üìä\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create PDF Report\n",
    "# pdf = FPDF()\n",
    "# pdf.set_auto_page_break(auto=True, margin=15)\n",
    "# pdf.add_page()\n",
    "\n",
    "# # ‚úÖ Load all font styles\n",
    "# pdf.add_font(\"DejaVu\", \"\", \"DejaVuSans.ttf\", uni=True)  # Regular\n",
    "# pdf.add_font(\"DejaVu\", \"B\", \"DejaVuSans-Bold.ttf\", uni=True)  # Bold\n",
    "# pdf.add_font(\"DejaVu\", \"I\", \"DejaVuSans-Oblique.ttf\", uni=True)  # Italic\n",
    "# pdf.add_font(\"DejaVu\", \"BI\", \"DejaVuSans-BoldOblique.ttf\", uni=True)  # Bold Italic\n",
    "\n",
    "# pdf.set_font(\"DejaVu\", \"\", 12)  # Use regular font\n",
    "\n",
    "# # ‚úÖ Ensure text fields are not empty\n",
    "# def safe_text(text):\n",
    "#     return text if text.strip() else \"No data available\"\n",
    "\n",
    "# jena_data_summary = safe_text(jena_data_summary)\n",
    "# ai_generated_report = safe_text(ai_generated_report)\n",
    "\n",
    "# # üìå Report Title\n",
    "# pdf.set_font(\"DejaVu\", \"B\", 16)\n",
    "# pdf.cell(200, 10, \"AI-Generated Analytical Report for Jena\", ln=True, align=\"C\")\n",
    "\n",
    "# # üìå Summary Section\n",
    "# pdf.set_font(\"DejaVu\", \"B\", 12)\n",
    "# pdf.cell(200, 10, \"Engagement Summary\", ln=True)\n",
    "# pdf.set_font(\"DejaVu\", \"\", 12)\n",
    "# pdf.multi_cell(190, 10, jena_data_summary)\n",
    "\n",
    "# # üìå AI-Generated Analysis\n",
    "# pdf.set_font(\"DejaVu\", \"B\", 12)\n",
    "# pdf.cell(200, 10, \"AI-Generated Insights\", ln=True)\n",
    "# pdf.set_font(\"DejaVu\", \"\", 12)\n",
    "# pdf.multi_cell(190, 10, ai_generated_report)\n",
    "\n",
    "# # üìå Additional Insights\n",
    "# pdf.set_font(\"DejaVu\", \"B\", 12)\n",
    "# pdf.cell(200, 10, \"Detailed Data Analysis\", ln=True)\n",
    "# pdf.set_font(\"DejaVu\", \"\", 12)\n",
    "# pdf.multi_cell(190, 10, f\"üìå Most Discussed Topics: {', '.join([word for word, count in keyword_counts[:10]])}\")\n",
    "# pdf.multi_cell(190, 10, f\"üìå Most Liked Comments: {most_liked_comments.to_string()}\")\n",
    "# pdf.multi_cell(190, 10, f\"üìå Peak Commenting Hours: {hourly_distribution.to_string()}\")\n",
    "# pdf.multi_cell(190, 10, f\"üìå Peak Commenting Days: {daily_distribution.to_string()}\")\n",
    "# pdf.multi_cell(190, 10, f\"üìå Most Supported Proposals: {most_supported_proposals.to_string()}\")\n",
    "# pdf.multi_cell(190, 10, f\"üìå Most Controversial Comments: {most_controversial_comments.to_string()}\")\n",
    "\n",
    "# # üìå Insert Charts (Ensure files exist before adding)\n",
    "# def safe_add_image(pdf, path, x=50, w=100):\n",
    "#     if os.path.exists(path):\n",
    "#         pdf.image(path, x=x, w=w)\n",
    "#     else:\n",
    "#         print(f\"‚ö†Ô∏è Warning: Image not found - {path}\")\n",
    "\n",
    "# safe_add_image(pdf, \"jena_wordcloud.png\")\n",
    "# safe_add_image(pdf, \"jena_active_users.png\")\n",
    "# safe_add_image(pdf, \"jena_sentiment_distribution.png\")\n",
    "\n",
    "# # ‚úÖ Save PDF\n",
    "# pdf_path = \"jena_ai_report.pdf\"\n",
    "# pdf.output(pdf_path, \"F\")\n",
    "\n",
    "# print(f\"‚úÖ AI Report Successfully Generated: {pdf_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----\n",
      "\n",
      "WeasyPrint could not import some external libraries. Please carefully follow the installation steps before reporting an issue:\n",
      "https://doc.courtbouillon.org/weasyprint/stable/first_steps.html#installation\n",
      "https://doc.courtbouillon.org/weasyprint/stable/first_steps.html#troubleshooting \n",
      "\n",
      "-----\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot load library 'libgobject-2.0-0': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libgobject-2.0-0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjinja2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Environment, FileSystemLoader\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mweasyprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Data for the report (replace with your actual data)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rusel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\weasyprint\\__init__.py:425\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m, string, base_url, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;66;03m# Work around circular imports.\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcss\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_stylesheet  \u001b[38;5;66;03m# noqa: I001, E402\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhtml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     HTML5_UA_COUNTER_STYLE, HTML5_UA_STYLESHEET, HTML5_UA_FORM_STYLESHEET,\n\u001b[0;32m    428\u001b[0m     HTML5_PH_STYLESHEET)\n\u001b[0;32m    429\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocument\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Document, Page  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Rusel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\weasyprint\\css\\__init__.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01murls\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m URLFetchingError, get_url_attribute, url_join\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m counters, media_queries\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomputed_values\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPUTER_FUNCTIONS\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m INHERITED, INITIAL_NOT_COMPUTED, INITIAL_VALUES, ZERO_PIXELS\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_declarations\n",
      "File \u001b[1;32mc:\\Users\\Rusel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\weasyprint\\css\\computed_values.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtinycss2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolor4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_color\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LOGGER\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mffi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FROM_UNITS, ffi, pango\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mline_break\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Layout, first_line_metrics\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01murls\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_link_attribute\n",
      "File \u001b[1;32mc:\\Users\\Rusel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\weasyprint\\text\\ffi.py:447\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m suppress((\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m)):\n\u001b[0;32m    445\u001b[0m             os\u001b[38;5;241m.\u001b[39madd_dll_directory(dll_directory)\n\u001b[1;32m--> 447\u001b[0m gobject \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mffi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlibgobject-2.0-0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgobject-2.0-0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgobject-2.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlibgobject-2.0.so.0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlibgobject-2.0.dylib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlibgobject-2.0-0.dll\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m pango \u001b[38;5;241m=\u001b[39m _dlopen(\n\u001b[0;32m    451\u001b[0m     ffi, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibpango-1.0-0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpango-1.0-0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpango-1.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibpango-1.0.so.0\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibpango-1.0.dylib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibpango-1.0-0.dll\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    453\u001b[0m harfbuzz \u001b[38;5;241m=\u001b[39m _dlopen(\n\u001b[0;32m    454\u001b[0m     ffi, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibharfbuzz-0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mharfbuzz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mharfbuzz-0.0\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    455\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibharfbuzz.so.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibharfbuzz.0.dylib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlibharfbuzz-0.dll\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rusel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\weasyprint\\text\\ffi.py:435\u001b[0m, in \u001b[0;36m_dlopen\u001b[1;34m(ffi, allow_fail, *names)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;66;03m# Re-raise the exception.\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-----\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeasyPrint could not import some external libraries. Please \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_steps.html#troubleshooting\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-----\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m--> 435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mffi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rusel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cffi\\api.py:150\u001b[0m, in \u001b[0;36mFFI.dlopen\u001b[1;34m(self, name, flags)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdlopen(name): name must be a file name, None, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor an already-opened \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoid *\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m handle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 150\u001b[0m     lib, function_cache \u001b[38;5;241m=\u001b[39m \u001b[43m_make_ffi_library\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_caches\u001b[38;5;241m.\u001b[39mappend(function_cache)\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libraries\u001b[38;5;241m.\u001b[39mappend(lib)\n",
      "File \u001b[1;32mc:\\Users\\Rusel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cffi\\api.py:832\u001b[0m, in \u001b[0;36m_make_ffi_library\u001b[1;34m(ffi, libname, flags)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_make_ffi_library\u001b[39m(ffi, libname, flags):\n\u001b[0;32m    831\u001b[0m     backend \u001b[38;5;241m=\u001b[39m ffi\u001b[38;5;241m.\u001b[39m_backend\n\u001b[1;32m--> 832\u001b[0m     backendlib \u001b[38;5;241m=\u001b[39m \u001b[43m_load_backend_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    834\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maccessor_function\u001b[39m(name):\n",
      "File \u001b[1;32mc:\\Users\\Rusel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\cffi\\api.py:827\u001b[0m, in \u001b[0;36m_load_backend_lib\u001b[1;34m(backend, name, flags)\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    826\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.  Additionally, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (first_error, msg)\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mload_library(path, flags)\n",
      "\u001b[1;31mOSError\u001b[0m: cannot load library 'libgobject-2.0-0': error 0x7e.  Additionally, ctypes.util.find_library() did not manage to locate a library called 'libgobject-2.0-0'"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from jinja2 import Environment, FileSystemLoader\n",
    "# from weasyprint import HTML\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Data for the report (replace with your actual data)\n",
    "# city = \"Jena\"\n",
    "# data = {\n",
    "#     \"city\": city,\n",
    "#     \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "#     \"summary\": \"This is a summary of civic engagement in Jena.\",\n",
    "#     \"ai_insights\": \"AI-generated insights about civic engagement in Jena.\",\n",
    "#     \"most_discussed_topics\": \", \".join([\"Jena\", \"Stra√üenbahn\", \"Bahnhof\", \"Stadt\", \"finden\"]),\n",
    "#     \"most_liked_comments\": \"Most liked comments data here.\",\n",
    "#     \"peak_hours\": \"Peak commenting hours data here.\",\n",
    "#     \"peak_days\": \"Peak commenting days data here.\",\n",
    "#     \"most_supported_proposals\": \"Most supported proposals data here.\",\n",
    "#     \"most_controversial_comments\": \"Most controversial comments data here.\",\n",
    "#     \"wordcloud_path\": \"jena_wordcloud.png\",\n",
    "#     \"active_users_plot_path\": \"jena_active_users.png\",\n",
    "#     \"sentiment_plot_path\": \"jena_sentiment_distribution.png\",\n",
    "# }\n",
    "\n",
    "# # Load the Jinja2 template\n",
    "# env = Environment(loader=FileSystemLoader('.'))\n",
    "# template = env.get_template('report_template.html')\n",
    "\n",
    "# # Render the HTML\n",
    "# html_out = template.render(data)\n",
    "\n",
    "# # Save HTML to a file (optional)\n",
    "# html_file_path = f\"{city}_report.html\"\n",
    "# with open(html_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(html_out)\n",
    "\n",
    "# # Convert HTML to PDF using WeasyPrint\n",
    "# pdf_file_path = f\"{city}_report.pdf\"\n",
    "# HTML(string=html_out).write_pdf(pdf_file_path)\n",
    "\n",
    "# print(f\"‚úÖ Report generated: {pdf_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "wkhtmltopdf reported an error:\nExit with code 1 due to network error: ProtocolUnknownError\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Convert HTML to PDF\u001b[39;00m\n\u001b[0;32m     52\u001b[0m pdf_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcity\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_report.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 53\u001b[0m \u001b[43mpdfkit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpdfkit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfiguration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwkhtmltopdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwkhtmltopdf_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Report generated: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Rusel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pdfkit\\api.py:75\u001b[0m, in \u001b[0;36mfrom_string\u001b[1;34m(input, output_path, options, toc, cover, css, configuration, cover_first, verbose)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03mConvert given string or strings to PDF document\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124;03mReturns: True on success\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     72\u001b[0m r \u001b[38;5;241m=\u001b[39m PDFKit(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m'\u001b[39m, options\u001b[38;5;241m=\u001b[39moptions, toc\u001b[38;5;241m=\u001b[39mtoc, cover\u001b[38;5;241m=\u001b[39mcover, css\u001b[38;5;241m=\u001b[39mcss,\n\u001b[0;32m     73\u001b[0m            configuration\u001b[38;5;241m=\u001b[39mconfiguration, cover_first\u001b[38;5;241m=\u001b[39mcover_first, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Rusel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pdfkit\\pdfkit.py:201\u001b[0m, in \u001b[0;36mPDFKit.to_pdf\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    199\u001b[0m stderr \u001b[38;5;241m=\u001b[39m stderr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    200\u001b[0m exit_code \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreturncode\n\u001b[1;32m--> 201\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexit_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Since wkhtmltopdf sends its output to stderr we will capture it\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# and properly send to stdout\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--quiet\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m args:\n",
      "File \u001b[1;32mc:\\Users\\Rusel\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pdfkit\\pdfkit.py:155\u001b[0m, in \u001b[0;36mPDFKit.handle_error\u001b[1;34m(exit_code, stderr)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    150\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou will need to run wkhtmltopdf within a \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvirtual\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m X server.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    151\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGo to the link below for more information\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    152\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/JazzCore/python-pdfkit/wiki/Using-wkhtmltopdf-without-X-server\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m stderr)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stderr:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwkhtmltopdf reported an error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m stderr)\n\u001b[0;32m    157\u001b[0m error_msg \u001b[38;5;241m=\u001b[39m stderr \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown Error\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwkhtmltopdf exited with non-zero code \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m. error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(exit_code, error_msg))\n",
      "\u001b[1;31mOSError\u001b[0m: wkhtmltopdf reported an error:\nExit with code 1 due to network error: ProtocolUnknownError\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "import pdfkit\n",
    "from datetime import datetime\n",
    "\n",
    "# Specify the path to wkhtmltopdf\n",
    "wkhtmltopdf_path = r'C:\\Program Files\\wkhtmltopdf\\bin\\wkhtmltopdf.exe'  # Update this path\n",
    "\n",
    "# Data for the report (replace with your actual data)\n",
    "city = \"Jena\"\n",
    "data = {\n",
    "    \"city\": city,\n",
    "    \"date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"summary\": \"This is a summary of civic engagement in Jena.\",\n",
    "    \"ai_insights\": \"AI-generated insights about civic engagement in Jena.\",\n",
    "    \"most_discussed_topics\": \", \".join([\"Jena\", \"Stra√üenbahn\", \"Bahnhof\", \"Stadt\", \"finden\"]),\n",
    "    \"most_liked_comments\": \"Most liked comments data here.\",\n",
    "    \"peak_hours\": \"Peak commenting hours data here.\",\n",
    "    \"peak_days\": \"Peak commenting days data here.\",\n",
    "    \"most_supported_proposals\": \"Most supported proposals data here.\",\n",
    "    \"most_controversial_comments\": \"Most controversial comments data here.\",\n",
    "    \"wordcloud_path\": \"jena_wordcloud.png\",  # Relative path\n",
    "    \"active_users_plot_path\": \"jena_active_users.png\",  # Relative path\n",
    "    \"sentiment_plot_path\": \"jena_sentiment_distribution.png\",  # Relative path\n",
    "}\n",
    "\n",
    "# Convert relative paths to absolute paths\n",
    "data[\"wordcloud_path\"] = os.path.abspath(data[\"wordcloud_path\"])\n",
    "data[\"active_users_plot_path\"] = os.path.abspath(data[\"active_users_plot_path\"])\n",
    "data[\"sentiment_plot_path\"] = os.path.abspath(data[\"sentiment_plot_path\"])\n",
    "\n",
    "# Load the Jinja2 template\n",
    "env = Environment(loader=FileSystemLoader('.'))\n",
    "template = env.get_template('report_template.html')\n",
    "\n",
    "# Render the HTML\n",
    "html_out = template.render(data)\n",
    "\n",
    "# Save HTML to a file (optional)\n",
    "html_file_path = f\"{city}_report.html\"\n",
    "with open(html_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html_out)\n",
    "\n",
    "# PDF options to disable printer interaction and suppress warnings\n",
    "options = {\n",
    "    'quiet': '',  # Suppress warnings and errors\n",
    "    'disable-local-file-access': '',  # Prevent access to local files\n",
    "    'no-pdf-compression': '',  # Disable PDF compression (avoids printer interaction)\n",
    "}\n",
    "\n",
    "# Convert HTML to PDF\n",
    "pdf_file_path = f\"{city}_report.pdf\"\n",
    "pdfkit.from_string(html_out, pdf_file_path, configuration=pdfkit.configuration(wkhtmltopdf=wkhtmltopdf_path), options=options)\n",
    "\n",
    "print(f\"‚úÖ Report generated: {pdf_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City\n",
       "Augsburg             24\n",
       "Bochum               24\n",
       "Detmold              24\n",
       "Siegburg             24\n",
       "Flensburg            23\n",
       "Wuerzburg            22\n",
       "Muenchen             19\n",
       "Jena                 19\n",
       "Unterschleissheim    18\n",
       "Mitren               14\n",
       "Bamberg              14\n",
       "Pforzheim            12\n",
       "Kempten              10\n",
       "Amberg                7\n",
       "Linz                  6\n",
       "Trier                 6\n",
       "Mitmachgemein         4\n",
       "Stutensee             2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projects_df['City'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Proposed for Project</th>\n",
       "      <th>Description</th>\n",
       "      <th>Author</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Supporters</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/proposals/110-a...</td>\n",
       "      <td>Autofreier Bischofshut</td>\n",
       "      <td>Zukunftskonzepte f√ºr die Innenstadt</td>\n",
       "      <td>Wir fordern die Ausrufung des Klimanotstands, ...</td>\n",
       "      <td>Letzte Generation W√ºrzburg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/proposals/109-e...</td>\n",
       "      <td>E Scooter verbieten</td>\n",
       "      <td>Zukunftskonzepte f√ºr die Innenstadt</td>\n",
       "      <td>E Scooter sollten (im Innenstadtbereich) verbo...</td>\n",
       "      <td>Ccmuet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/proposals/108-b...</td>\n",
       "      <td>Barrierefrei ins Nautiland/LGS</td>\n",
       "      <td>Zukunftskonzepte f√ºr die Innenstadt</td>\n",
       "      <td>Nautiland - neu.\\r\\nUmweltstation - neu.\\r\\nZe...</td>\n",
       "      <td>AASeuffert</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/proposals/107-k...</td>\n",
       "      <td>Kinderabenteuer / Indoor Spielplatz / Smaland</td>\n",
       "      <td>Zukunftskonzepte f√ºr die Innenstadt</td>\n",
       "      <td>Es gibt zwar schon den FunPark f√ºr Kinder mit ...</td>\n",
       "      <td>ABlitz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/proposals/106-b...</td>\n",
       "      <td>B√§nke und \"Gr√ºn\" im neu gestalteten Bereich Ka...</td>\n",
       "      <td>Zukunftskonzepte f√ºr die Innenstadt</td>\n",
       "      <td>Die Baustelle von der Karmelitenstra√üe zum Vie...</td>\n",
       "      <td>Ccmuet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>https://machmit.augsburg.de/proposals/8-famili...</td>\n",
       "      <td>Familiennetz\\r\\nWe are family</td>\n",
       "      <td>Wie soll die digitale Plattform f√ºr Familien h...</td>\n",
       "      <td>2 Ideen</td>\n",
       "      <td>SSonja Poland - FSP B√§renkeller</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Augsburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>https://machmit.augsburg.de/proposals/7-famili...</td>\n",
       "      <td>Familien Hub</td>\n",
       "      <td>Wie soll die digitale Plattform f√ºr Familien h...</td>\n",
       "      <td>Ein Hub f√ºr Familien</td>\n",
       "      <td>CCPM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Augsburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>https://machmit.augsburg.de/proposals/21-windp...</td>\n",
       "      <td>Windprechtpark</td>\n",
       "      <td>Wie war der Sommer?</td>\n",
       "      <td>Der Winprechtpark ist ein k√ºhler Ort, hat aber...</td>\n",
       "      <td>Gguest_7cc4b24b-c70a-48f7-bb5e-ad399221e79a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Augsburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>https://machmit.augsburg.de/proposals/13-witte...</td>\n",
       "      <td>Wittelsbacher Park</td>\n",
       "      <td>Wie war der Sommer?</td>\n",
       "      <td>Sehr sch√∂ne Park mit viel Schatten. Etwas mehr...</td>\n",
       "      <td>UUli</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Augsburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>https://machmit.augsburg.de/proposals/12-siebe...</td>\n",
       "      <td>Siebentischwald</td>\n",
       "      <td>Wie war der Sommer?</td>\n",
       "      <td>Sch√∂n k√ºhl im Sommer dort!</td>\n",
       "      <td>GGastlo</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Augsburg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   URL  \\\n",
       "0    https://wuerzburg-mitmachen.de/proposals/110-a...   \n",
       "1    https://wuerzburg-mitmachen.de/proposals/109-e...   \n",
       "2    https://wuerzburg-mitmachen.de/proposals/108-b...   \n",
       "3    https://wuerzburg-mitmachen.de/proposals/107-k...   \n",
       "4    https://wuerzburg-mitmachen.de/proposals/106-b...   \n",
       "..                                                 ...   \n",
       "660  https://machmit.augsburg.de/proposals/8-famili...   \n",
       "661  https://machmit.augsburg.de/proposals/7-famili...   \n",
       "662  https://machmit.augsburg.de/proposals/21-windp...   \n",
       "663  https://machmit.augsburg.de/proposals/13-witte...   \n",
       "664  https://machmit.augsburg.de/proposals/12-siebe...   \n",
       "\n",
       "                                                 Title  \\\n",
       "0                               Autofreier Bischofshut   \n",
       "1                                  E Scooter verbieten   \n",
       "2                       Barrierefrei ins Nautiland/LGS   \n",
       "3        Kinderabenteuer / Indoor Spielplatz / Smaland   \n",
       "4    B√§nke und \"Gr√ºn\" im neu gestalteten Bereich Ka...   \n",
       "..                                                 ...   \n",
       "660                      Familiennetz\\r\\nWe are family   \n",
       "661                                       Familien Hub   \n",
       "662                                     Windprechtpark   \n",
       "663                                 Wittelsbacher Park   \n",
       "664                                    Siebentischwald   \n",
       "\n",
       "                                  Proposed for Project  \\\n",
       "0                  Zukunftskonzepte f√ºr die Innenstadt   \n",
       "1                  Zukunftskonzepte f√ºr die Innenstadt   \n",
       "2                  Zukunftskonzepte f√ºr die Innenstadt   \n",
       "3                  Zukunftskonzepte f√ºr die Innenstadt   \n",
       "4                  Zukunftskonzepte f√ºr die Innenstadt   \n",
       "..                                                 ...   \n",
       "660  Wie soll die digitale Plattform f√ºr Familien h...   \n",
       "661  Wie soll die digitale Plattform f√ºr Familien h...   \n",
       "662                                Wie war der Sommer?   \n",
       "663                                Wie war der Sommer?   \n",
       "664                                Wie war der Sommer?   \n",
       "\n",
       "                                           Description  \\\n",
       "0    Wir fordern die Ausrufung des Klimanotstands, ...   \n",
       "1    E Scooter sollten (im Innenstadtbereich) verbo...   \n",
       "2    Nautiland - neu.\\r\\nUmweltstation - neu.\\r\\nZe...   \n",
       "3    Es gibt zwar schon den FunPark f√ºr Kinder mit ...   \n",
       "4    Die Baustelle von der Karmelitenstra√üe zum Vie...   \n",
       "..                                                 ...   \n",
       "660                                            2 Ideen   \n",
       "661                               Ein Hub f√ºr Familien   \n",
       "662  Der Winprechtpark ist ein k√ºhler Ort, hat aber...   \n",
       "663  Sehr sch√∂ne Park mit viel Schatten. Etwas mehr...   \n",
       "664                         Sch√∂n k√ºhl im Sommer dort!   \n",
       "\n",
       "                                          Author  Comments  Supporters  \\\n",
       "0                     Letzte Generation W√ºrzburg       0.0        20.0   \n",
       "1                                         Ccmuet       0.0         2.0   \n",
       "2                                     AASeuffert       0.0         2.0   \n",
       "3                                         ABlitz       0.0         0.0   \n",
       "4                                         Ccmuet       0.0        12.0   \n",
       "..                                           ...       ...         ...   \n",
       "660              SSonja Poland - FSP B√§renkeller       0.0         0.0   \n",
       "661                                         CCPM       0.0         0.0   \n",
       "662  Gguest_7cc4b24b-c70a-48f7-bb5e-ad399221e79a       0.0         0.0   \n",
       "663                                         UUli       0.0         1.0   \n",
       "664                                      GGastlo       0.0         0.0   \n",
       "\n",
       "          City  \n",
       "0    Wuerzburg  \n",
       "1    Wuerzburg  \n",
       "2    Wuerzburg  \n",
       "3    Wuerzburg  \n",
       "4    Wuerzburg  \n",
       "..         ...  \n",
       "660   Augsburg  \n",
       "661   Augsburg  \n",
       "662   Augsburg  \n",
       "663   Augsburg  \n",
       "664   Augsburg  \n",
       "\n",
       "[665 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_proposals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
