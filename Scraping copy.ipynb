{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraper for 19 Cities\n",
    "\n",
    "This scraper extracts and organizes data into three main DataFrames:\n",
    "1. **`all_projects_df`**: Contains all projects from the websites.\n",
    "   - Columns: `Project URL`, `Project Title`, `Project Description`, `Proposal Count`, `City`\n",
    "\n",
    "2. **`all_proposals_df`**: Contains all proposals under projects.\n",
    "   - Columns: `URL`, `Title`, `Proposed for Project`, `Description`, `Author`, `Comments`, `Supporters`, `City`\n",
    "\n",
    "3. **`all_comments_df`**: Contains all comments under projects and proposals.\n",
    "   - Columns: `URL`, `Project`, `Text`, `Author`, `Likes`, `Dislikes`, `Date`, `City`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error scraping project at https://flensburg-mitmachen.dehttps://survey.lamapoll.de/Publikumspreis-Kommune-bewegt-Welt-2024: HTTPSConnectionPool(host='flensburg-mitmachen.dehttps', port=443): Max retries exceeded with url: /survey.lamapoll.de/Publikumspreis-Kommune-bewegt-Welt-2024 (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x0000018D29CE5AB0>: Failed to resolve 'flensburg-mitmachen.dehttps' ([Errno 11001] getaddrinfo failed)\"))\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Updated function to extract proposals from a project page\n",
    "def extract_proposals(soup, base_url):\n",
    "    proposals = []\n",
    "    proposal_items = soup.find_all('div', class_='resource-item proposal-list-item')\n",
    "\n",
    "    for proposal in proposal_items:\n",
    "        # Extract title\n",
    "        title_tag = proposal.find('a', class_='resource-item--title')\n",
    "        title = title_tag.get_text(strip=True) if title_tag else None\n",
    "\n",
    "        # Extract URL\n",
    "        url = base_url + title_tag['href'] if title_tag and 'href' in title_tag.attrs else None\n",
    "\n",
    "        # Extract description\n",
    "        description_tag = proposal.find('div', class_='resource-item--description')\n",
    "        description = description_tag.get_text(strip=True) if description_tag else None\n",
    "\n",
    "        # Extract author/username\n",
    "        author_tag = proposal.find('a', class_='resource-item--author')\n",
    "        author = author_tag.get_text(strip=True) if author_tag else None\n",
    "\n",
    "        # Extract number of comments\n",
    "        comments_tag = proposal.find('span', class_='comments')\n",
    "        comments = int(comments_tag.get_text(strip=True).split()[0]) if comments_tag else 0\n",
    "\n",
    "        # Extract number of supporters\n",
    "        supporters_tag = proposal.find('span', class_='total-supports')\n",
    "        supporters = int(supporters_tag.get_text(strip=True).split()[0]) if supporters_tag else 0\n",
    "\n",
    "        # Extract parent project\n",
    "        project_tag = proposal.find('a', class_='breadcrumbs-item')\n",
    "        proposed_for_project = project_tag.get_text(strip=True) if project_tag else None\n",
    "\n",
    "        proposals.append({\n",
    "            'URL': url,\n",
    "            'Title': title,\n",
    "            'Proposed for Project': proposed_for_project,\n",
    "            'Description': description,\n",
    "            'Author': author,\n",
    "            'Comments': comments,\n",
    "            'Supporters': supporters,\n",
    "        })\n",
    "    return proposals\n",
    "        proposals.append({\n",
    "            'URL': url,\n",
    "            'Title': title,\n",
    "            'Proposed for Project': proposed_for_project,\n",
    "            'Description': description,\n",
    "            'Author': author,\n",
    "            'Comments': comments,\n",
    "            'Supporters': supporters,\n",
    "        })\n",
    "    return proposals\n",
    "\n",
    "\n",
    "# Function to extract city name from the base URL\n",
    "def extract_city_name(base_url):\n",
    "    # Words to remove from the city name\n",
    "    remove_words = ['mitmachen', 'Mitmachen', 'mitwirken', 'Smarte', 'region', 'unser', 'mitgestalten', 'gestalten', 'machmit', 'dialog', 'consul', 'www', 'de', 'https', 'com']\n",
    "\n",
    "    # Split the URL into parts (by '.' or '/')\n",
    "    parts = base_url.replace('https://', '').replace('http://', '').split('.')\n",
    "    all_parts = [part.split('/')[0] for part in parts]  # Handle cases where \"/\" exists after domain\n",
    "\n",
    "    # Remove known unwanted words and empty strings\n",
    "    filtered_parts = [part for part in all_parts if part.lower() not in remove_words and part]\n",
    "\n",
    "    # Return the first relevant part (assumes city name is left after filtering)\n",
    "    city = filtered_parts[0].replace('-', ' ').capitalize() if filtered_parts else \"Unknown\"\n",
    "\n",
    "    # Remove unwanted words from city name\n",
    "    for word in remove_words:\n",
    "        city = city.replace(word, '')\n",
    "\n",
    "    return city.strip().capitalize()\n",
    "    return city.strip().capitalize()\n",
    "\n",
    "\n",
    "# Update project scraping to exclude comments\n",
    "def scrape_project_page_with_proposals(url, base_url, city):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to load project page: {url}\")\n",
    "        return None, []\n",
    "# Update project scraping to exclude comments\n",
    "def scrape_project_page_with_proposals(url, base_url, city):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to load project page: {url}\")\n",
    "        return None, []\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract project title\n",
    "    title_tag = soup.find('title')\n",
    "    project_title = title_tag.get_text(strip=True) if title_tag else None\n",
    "\n",
    "    # Extract project description\n",
    "    content_div = soup.find('div', class_='flex-layout')\n",
    "    description = content_div.get_text(strip=True) if content_div else None\n",
    "\n",
    "    # Extract proposals\n",
    "    proposals = extract_proposals(soup, base_url=base_url)\n",
    "\n",
    "    return {\n",
    "        'Project URL': url,\n",
    "        'Project Title': project_title,\n",
    "        'Project Description': description,\n",
    "        'Proposal Count': len(proposals),\n",
    "    }, proposals\n",
    "\n",
    "\n",
    "# Modified function to scrape projects with proposals\n",
    "def scrape_projects_with_proposals(main_url, base_url):\n",
    "    response = requests.get(main_url)\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to load main projects page: {main_url}\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all project links\n",
    "    links = soup.find_all('a', class_='resource-item--title')\n",
    "    project_links = [base_url + link['href'] for link in links if 'href' in link.attrs]\n",
    "\n",
    "    projects = []\n",
    "    all_proposals = []\n",
    "\n",
    "    for project_url in project_links:\n",
    "        try:\n",
    "            project_data, proposals = scrape_project_page_with_proposals(\n",
    "                project_url, base_url, extract_city_name(base_url)\n",
    "            )\n",
    "            if project_data:\n",
    "                projects.append(project_data)\n",
    "                all_proposals.extend(proposals)\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping project at {project_url}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(projects), pd.DataFrame(all_proposals)\n",
    "\n",
    "# List of websites (fixed flensburg-mitmachen.de base_url)\n",
    "websites = [\n",
    "    {\"main_url\": \"https://wuerzburg-mitmachen.de/projekts\", \"base_url\": \"https://wuerzburg-mitmachen.de\"},\n",
    "    {\"main_url\": \"https://mitmachen.siegburg.de/projekts\", \"base_url\": \"https://mitmachen.siegburg.de\"}, \n",
    "    {\"main_url\": \"https://mitmachen.jena.de/projekts\", \"base_url\": \"https://mitmachen.jena.de\"},\n",
    "    {\"main_url\": \"https://mitmachgemeinde.de/projekts\", \"base_url\": \"https://mitmachgemeinde.de\"},\n",
    "    {\"main_url\": \"https://bamberg-gestalten.de/projekts\", \"base_url\": \"https://bamberg-gestalten.de\"},\n",
    "    {\"main_url\": \"https://mitmachen-pforzheim.de/projekts\", \"base_url\": \"https://mitmachen-pforzheim.de\"},\n",
    "    {\"main_url\": \"https://bochum-mitgestalten.de/projekts\", \"base_url\": \"https://bochum-mitgestalten.de\"},\n",
    "    {\"main_url\": \"https://unser.muenchen.de/projekts\", \"base_url\": \"https://unser.muenchen.de\"},\n",
    "    {\"main_url\": \"https://mitreden.ilzerland.bayern/projekts\", \"base_url\": \"https://mitreden.ilzerland.bayern\"},\n",
    "    {\"main_url\": \"https://stutensee-mitwirken.de/projekts\", \"base_url\": \"https://stutensee-mitwirken.de\"},\n",
    "    {\"main_url\": \"https://consul.unterschleissheim.de/projekts\", \"base_url\": \"https://consul.unterschleissheim.de\"},\n",
    "    {\"main_url\": \"https://machmit.kempten.de/projekts\", \"base_url\": \"https://machmit.kempten.de\"},\n",
    "    {\"main_url\": \"https://consul.detmold-mitgestalten.de/projekts\", \"base_url\": \"https://consul.detmold-mitgestalten.de\"},\n",
    "    {\"main_url\": \"https://flensburg-mitmachen.de/projekts\", \"base_url\": \"https://flensburg-mitmachen.de\"},  # Fixed URL\n",
    "    {\"main_url\": \"https://mitmachen.amberg.de/projekts\", \"base_url\": \"https://mitmachen.amberg.de\"},\n",
    "    {\"main_url\": \"https://mitmachen.smarte-region-linz.de/projekts\", \"base_url\": \"https://mitmachen.smarte-region-linz.de\"},\n",
    "    {\"main_url\": \"https://mitgestalten.trier.de/projekts\", \"base_url\": \"https://mitgestalten.trier.de\"},\n",
    "    {\"main_url\": \"https://machmit.augsburg.de/projekts\", \"base_url\": \"https://machmit.augsburg.de\"}\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize empty DataFrames for all projects and proposals\n",
    "all_projects_df = pd.DataFrame()\n",
    "all_proposals_df = pd.DataFrame()\n",
    "\n",
    "# Main loop to scrape all websites\n",
    "for site in websites:\n",
    "    main_url = site[\"main_url\"]\n",
    "    base_url = site[\"base_url\"]\n",
    "\n",
    "    city = extract_city_name(base_url)\n",
    "\n",
    "    try:\n",
    "        # Scrape projects and proposals\n",
    "        projects_df, proposals_df = scrape_projects_with_proposals(main_url, base_url)\n",
    "\n",
    "        # Add a 'City' column to all DataFrames\n",
    "        projects_df['City'] = city\n",
    "        proposals_df['City'] = city\n",
    "\n",
    "        # Append results to the combined DataFrames\n",
    "        all_projects_df = pd.concat([all_projects_df, projects_df], ignore_index=True)\n",
    "        all_proposals_df = pd.concat([all_proposals_df, proposals_df], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to scrape {main_url} - {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>Proposed for Project</th>\n",
       "      <th>Description</th>\n",
       "      <th>Author</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Supporters</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/proposals/110-autofreier-bischofshut</td>\n",
       "      <td>Autofreier Bischofshut</td>\n",
       "      <td>Zukunftskonzepte für die Innenstadt</td>\n",
       "      <td>Wir fordern die Ausrufung des Klimanotstands, damit Belange unseres Klimas vor das wirtschaftlic...</td>\n",
       "      <td>Letzte Generation Würzburg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/proposals/109-e-scooter-verbieten</td>\n",
       "      <td>E Scooter verbieten</td>\n",
       "      <td>Zukunftskonzepte für die Innenstadt</td>\n",
       "      <td>E Scooter sollten (im Innenstadtbereich) verboten werden. Diese werden häufig willkürlich abgest...</td>\n",
       "      <td>Ccmuet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/proposals/108-barrierefrei-ins-nautiland-lgs</td>\n",
       "      <td>Barrierefrei ins Nautiland/LGS</td>\n",
       "      <td>Zukunftskonzepte für die Innenstadt</td>\n",
       "      <td>Nautiland - neu.\\r\\nUmweltstation - neu.\\r\\nZellertorauffahrt - neu.\\r\\nLeider fehlen die barrie...</td>\n",
       "      <td>AASeuffert</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/proposals/107-kinderabenteuer-indoor-spielplatz-smaland</td>\n",
       "      <td>Kinderabenteuer / Indoor Spielplatz / Smaland</td>\n",
       "      <td>Zukunftskonzepte für die Innenstadt</td>\n",
       "      <td>Es gibt zwar schon den FunPark für Kinder mit Trampolinhalle etc. in der Nähe der Nürnberger Str...</td>\n",
       "      <td>ABlitz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/proposals/106-banke-und-grun-im-neu-gestalteten-bereich-karmelite...</td>\n",
       "      <td>Bänke und \"Grün\" im neu gestalteten Bereich Karmelitenstraße/Vierröhr...</td>\n",
       "      <td>Zukunftskonzepte für die Innenstadt</td>\n",
       "      <td>Die Baustelle von der Karmelitenstraße zum Vierröhrenbrunnen wurde vor kurzem abgeschlossen. Die...</td>\n",
       "      <td>Ccmuet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   URL  \\\n",
       "0                                  https://wuerzburg-mitmachen.de/proposals/110-autofreier-bischofshut   \n",
       "1                                     https://wuerzburg-mitmachen.de/proposals/109-e-scooter-verbieten   \n",
       "2                          https://wuerzburg-mitmachen.de/proposals/108-barrierefrei-ins-nautiland-lgs   \n",
       "3               https://wuerzburg-mitmachen.de/proposals/107-kinderabenteuer-indoor-spielplatz-smaland   \n",
       "4  https://wuerzburg-mitmachen.de/proposals/106-banke-und-grun-im-neu-gestalteten-bereich-karmelite...   \n",
       "\n",
       "                                                                      Title  \\\n",
       "0                                                    Autofreier Bischofshut   \n",
       "1                                                       E Scooter verbieten   \n",
       "2                                            Barrierefrei ins Nautiland/LGS   \n",
       "3                             Kinderabenteuer / Indoor Spielplatz / Smaland   \n",
       "4  Bänke und \"Grün\" im neu gestalteten Bereich Karmelitenstraße/Vierröhr...   \n",
       "\n",
       "                  Proposed for Project  \\\n",
       "0  Zukunftskonzepte für die Innenstadt   \n",
       "1  Zukunftskonzepte für die Innenstadt   \n",
       "2  Zukunftskonzepte für die Innenstadt   \n",
       "3  Zukunftskonzepte für die Innenstadt   \n",
       "4  Zukunftskonzepte für die Innenstadt   \n",
       "\n",
       "                                                                                           Description  \\\n",
       "0  Wir fordern die Ausrufung des Klimanotstands, damit Belange unseres Klimas vor das wirtschaftlic...   \n",
       "1  E Scooter sollten (im Innenstadtbereich) verboten werden. Diese werden häufig willkürlich abgest...   \n",
       "2  Nautiland - neu.\\r\\nUmweltstation - neu.\\r\\nZellertorauffahrt - neu.\\r\\nLeider fehlen die barrie...   \n",
       "3  Es gibt zwar schon den FunPark für Kinder mit Trampolinhalle etc. in der Nähe der Nürnberger Str...   \n",
       "4  Die Baustelle von der Karmelitenstraße zum Vierröhrenbrunnen wurde vor kurzem abgeschlossen. Die...   \n",
       "\n",
       "                       Author  Comments  Supporters       City  \n",
       "0  Letzte Generation Würzburg       0.0        20.0  Wuerzburg  \n",
       "1                      Ccmuet       0.0         2.0  Wuerzburg  \n",
       "2                  AASeuffert       0.0         2.0  Wuerzburg  \n",
       "3                      ABlitz       0.0         0.0  Wuerzburg  \n",
       "4                      Ccmuet       0.0        12.0  Wuerzburg  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_proposals_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project URL</th>\n",
       "      <th>Project Title</th>\n",
       "      <th>Project Description</th>\n",
       "      <th>Proposal Count</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/grombuehl-zukunftssicher</td>\n",
       "      <td>Energetisches Quartierskonzept für Grombühl</td>\n",
       "      <td>Grombühl 2040 - ein SzenarioDie Straßen Grombühls sind grüner, ruhiger und voller Leben. Das „Qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/mobilitaetsplan</td>\n",
       "      <td>Mobilitätsplan 2040</td>\n",
       "      <td>Mobilitätsplan 2040 für die Stadt Würzburg: Jetzt mitmachen!Aktuell erstellt die Stadt Würzburg ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/zukunftsregion</td>\n",
       "      <td>Zukunftsregion Würzburg</td>\n",
       "      <td>Zukunftsregion Würzburg: Jetzt aktiv mitgestalten!Die Stadt und der Landkreis Würzburg wollen ih...</td>\n",
       "      <td>0</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/zukunftskonzepte-fuer-die-innenstadt</td>\n",
       "      <td>Zukunftskonzepte für die Innenstadt</td>\n",
       "      <td>Wie soll die Würzburger Innenstadt von morgen aussehen? Was wünschen sich Bürger:innen, Einzelhä...</td>\n",
       "      <td>24</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://wuerzburg-mitmachen.de/klimaanpassung</td>\n",
       "      <td>Klimaanpassung</td>\n",
       "      <td>Klimaanpassungsstrategie für die Stadt Würzburg: Jetzt mitmachen!Würzburg - Seit Anfang 2024 era...</td>\n",
       "      <td>14</td>\n",
       "      <td>Wuerzburg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           Project URL  \\\n",
       "0              https://wuerzburg-mitmachen.de/grombuehl-zukunftssicher   \n",
       "1                       https://wuerzburg-mitmachen.de/mobilitaetsplan   \n",
       "2                        https://wuerzburg-mitmachen.de/zukunftsregion   \n",
       "3  https://wuerzburg-mitmachen.de/zukunftskonzepte-fuer-die-innenstadt   \n",
       "4                        https://wuerzburg-mitmachen.de/klimaanpassung   \n",
       "\n",
       "                                 Project Title  \\\n",
       "0  Energetisches Quartierskonzept für Grombühl   \n",
       "1                          Mobilitätsplan 2040   \n",
       "2                      Zukunftsregion Würzburg   \n",
       "3          Zukunftskonzepte für die Innenstadt   \n",
       "4                               Klimaanpassung   \n",
       "\n",
       "                                                                                   Project Description  \\\n",
       "0  Grombühl 2040 - ein SzenarioDie Straßen Grombühls sind grüner, ruhiger und voller Leben. Das „Qu...   \n",
       "1  Mobilitätsplan 2040 für die Stadt Würzburg: Jetzt mitmachen!Aktuell erstellt die Stadt Würzburg ...   \n",
       "2  Zukunftsregion Würzburg: Jetzt aktiv mitgestalten!Die Stadt und der Landkreis Würzburg wollen ih...   \n",
       "3  Wie soll die Würzburger Innenstadt von morgen aussehen? Was wünschen sich Bürger:innen, Einzelhä...   \n",
       "4  Klimaanpassungsstrategie für die Stadt Würzburg: Jetzt mitmachen!Würzburg - Seit Anfang 2024 era...   \n",
       "\n",
       "   Proposal Count       City  \n",
       "0               0  Wuerzburg  \n",
       "1               0  Wuerzburg  \n",
       "2               0  Wuerzburg  \n",
       "3              24  Wuerzburg  \n",
       "4              14  Wuerzburg  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_projects_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BurgerBudgets in Jena (2024, 23, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('siegburg_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Username\n",
       "Lars Löw           34\n",
       "klaus.kleiner77    32\n",
       "Der,wo             31\n",
       "PM                 18\n",
       "Klaus.kleiner77    16\n",
       "                   ..\n",
       "Julius Kuhn         1\n",
       "Juliane88           1\n",
       "Juliane Fuchs       1\n",
       "Julian Sing         1\n",
       "🐙                   1\n",
       "Name: count, Length: 387, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional cleaaning and structuring for Sieburg (review if it's needed) !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# # Enhanced function to extract all logical parts, including \"Unterstützer*innen\"\n",
    "# def extract_full_data_with_supporters(content):\n",
    "#     # Extract title (everything before the first date)\n",
    "#     title_match = re.search(r'^(.*?)(\\r|\\d{1,2}\\.\\s\\w+\\s\\d{4})', content)\n",
    "#     title = title_match.group(1).strip() if title_match else None\n",
    "\n",
    "#     # Extract date\n",
    "#     date_match = re.search(r'\\d{1,2}\\.\\s\\w+\\s\\d{4}', content)\n",
    "#     date = date_match.group(0) if date_match else None\n",
    "\n",
    "#     # Extract comments count\n",
    "#     comments_match = re.search(r'(\\d+)\\sKommentare', content)\n",
    "#     comments = int(comments_match.group(1)) if comments_match else 0\n",
    "\n",
    "#     # Extract tags (sections with numbers or + signs)\n",
    "#     tags_match = re.findall(r'(\\d{1,2}[-+]\\d{1,2}|\\d{2}\\+)', content)\n",
    "#     tags = ', '.join(tags_match) if tags_match else None\n",
    "\n",
    "#     # Extract description (everything after \"Geselliges Beisammensein\" or similar patterns)\n",
    "#     description_start = re.search(r'(Geselliges Beisammensein|Angebotslandkarte)', content)\n",
    "#     description = content[description_start.start():].strip() if description_start else None\n",
    "\n",
    "#     # Extract username\n",
    "#     username_match = re.search(r'(\\w+\\s\\w+|Beigetreten am:.*?\\d{4})', content)\n",
    "#     username = username_match.group(1).split('Beigetreten am:')[0].strip() if username_match else None\n",
    "\n",
    "#     # Extract Vorschläge count\n",
    "#     vorschlaege_match = re.search(r'Vorschläge(\\d+)', content)\n",
    "#     vorschlaege = int(vorschlaege_match.group(1)) if vorschlaege_match else 0\n",
    "\n",
    "#     # Extract Konto verification status\n",
    "#     konto_match = re.search(r'(Konto\\s(verifiziert|ist nicht verifiziert))', content)\n",
    "#     konto_status = konto_match.group(2) if konto_match else None\n",
    "\n",
    "#     # # Extract registration date\n",
    "#     # registration_match = re.search(r'Beigetreten am:\\s(\\d{1,2}\\.\\s\\w+\\s\\d{4})', content)\n",
    "#     # registration_date = registration_match.group(1) if registration_match else None\n",
    "\n",
    "#     # Extract number of Unterstützer*innen\n",
    "#     supporters_match = re.search(r'(\\d+)\\sUnterstützer\\*in', content)\n",
    "#     supporters = int(supporters_match.group(1)) if supporters_match else 0\n",
    "\n",
    "#     return title, date, comments, tags, description, username, vorschlaege, konto_status, supporters\n",
    "\n",
    "# # Apply the enhanced function to the DataFrame and create new columns\n",
    "# df_sieburg[['Title', 'Date', 'Comments', 'Tags', 'Description', 'Username', 'Vorschläge', 'Konto Status', 'Supporters']] = df_sieburg['Content'].apply(\n",
    "#     lambda x: pd.Series(extract_full_data_with_supporters(x))\n",
    "# )\n",
    "\n",
    "\n",
    "# # Function to clean description considering keywords, numeric patterns, and refined starting logic\n",
    "# def clean_description_advanced(content):\n",
    "#     # Define keywords that mark the beginning of the description\n",
    "#     keywords = [\n",
    "#         'Geselliges Beisammensein', 'Natur', 'Hilfe & Beratung', 'Bildung', \n",
    "#         'Musik', 'Bewegung', 'Glaube', 'Kulinarisches', 'Kunst & Kultur', 'Sonstiges',\n",
    "#     ]\n",
    "    \n",
    "#     # Check for keywords first\n",
    "#     for keyword in keywords:\n",
    "#         if keyword in content:\n",
    "#             start_idx = content.find(keyword) + len(keyword)\n",
    "#             description = content[start_idx:].strip()\n",
    "#             description = re.split(r'(Kommentare\\(.*?\\)|registrieren)', description)[0].strip()\n",
    "#             return description\n",
    "\n",
    "#     # If no keyword is found, check for numeric patterns like \"18-24, 25-49, etc.\"\n",
    "#     numeric_pattern = re.search(r'(\\d{1,2}[-+]\\d{1,2}|\\d{2}\\+)', content)\n",
    "#     if numeric_pattern:\n",
    "#         start_idx = numeric_pattern.end()\n",
    "#         description = content[start_idx:].strip()\n",
    "#         description = re.split(r'(Kommentare\\(.*?\\)|registrieren)', description)[0].strip()\n",
    "#         return description\n",
    "\n",
    "#     # As a fallback, find the first capital letter, quote, or digit to mark the start\n",
    "#     fallback_match = re.search(r'[A-Z\"0-9]', content)\n",
    "#     if fallback_match:\n",
    "#         start_idx = fallback_match.start()\n",
    "#         description = content[start_idx:].strip()\n",
    "#         description = re.split(r'(Kommentare\\(.*?\\)|registrieren)', description)[0].strip()\n",
    "#         return description\n",
    "\n",
    "#     # If nothing works, return the content as is\n",
    "#     return content\n",
    "\n",
    "# # Apply the advanced cleaning function to the Description column\n",
    "# df_sieburg['Description'] = df_sieburg['Content'].apply(clean_description_advanced)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
